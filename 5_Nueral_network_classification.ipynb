{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Nueral_network_classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPbkzqIF7gk7gkVruk4JDIb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/urvashipathak/ML/blob/main/5_Nueral_network_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUiOQnHgMlRt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data= pd.read_csv('/content/drive/MyDrive/diabetes.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "5VjUZZptPNTl",
        "outputId": "f27c883c-bb33-4011-9dd0-1ae9bbff195b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0            6      148             72             35        0  33.6   \n",
              "1            1       85             66             29        0  26.6   \n",
              "2            8      183             64              0        0  23.3   \n",
              "3            1       89             66             23       94  28.1   \n",
              "4            0      137             40             35      168  43.1   \n",
              "5            5      116             74              0        0  25.6   \n",
              "6            3       78             50             32       88  31.0   \n",
              "7           10      115              0              0        0  35.3   \n",
              "8            2      197             70             45      543  30.5   \n",
              "9            8      125             96              0        0   0.0   \n",
              "\n",
              "   DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                     0.627   50        1  \n",
              "1                     0.351   31        0  \n",
              "2                     0.672   32        1  \n",
              "3                     0.167   21        0  \n",
              "4                     2.288   33        1  \n",
              "5                     0.201   30        0  \n",
              "6                     0.248   26        1  \n",
              "7                     0.134   29        0  \n",
              "8                     0.158   53        1  \n",
              "9                     0.232   54        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a1e36331-ba99-4964-8fe7-9cea82e78a7f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>116</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25.6</td>\n",
              "      <td>0.201</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3</td>\n",
              "      <td>78</td>\n",
              "      <td>50</td>\n",
              "      <td>32</td>\n",
              "      <td>88</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0.248</td>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>10</td>\n",
              "      <td>115</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>35.3</td>\n",
              "      <td>0.134</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2</td>\n",
              "      <td>197</td>\n",
              "      <td>70</td>\n",
              "      <td>45</td>\n",
              "      <td>543</td>\n",
              "      <td>30.5</td>\n",
              "      <td>0.158</td>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>8</td>\n",
              "      <td>125</td>\n",
              "      <td>96</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.232</td>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1e36331-ba99-4964-8fe7-9cea82e78a7f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a1e36331-ba99-4964-8fe7-9cea82e78a7f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a1e36331-ba99-4964-8fe7-9cea82e78a7f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns\n",
        "data.values\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gza800-oPvug",
        "outputId": "d6195379-4601-4d57-cc61-0ba55340e90c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
              "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
              "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
              "       ...,\n",
              "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
              "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
              "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.tail(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "8y94S3l8Qsy5",
        "outputId": "2cf2a89a-2c21-4336-d70a-9f2a0ff3be0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "758            1      106             76              0        0  37.5   \n",
              "759            6      190             92              0        0  35.5   \n",
              "760            2       88             58             26       16  28.4   \n",
              "761            9      170             74             31        0  44.0   \n",
              "762            9       89             62              0        0  22.5   \n",
              "763           10      101             76             48      180  32.9   \n",
              "764            2      122             70             27        0  36.8   \n",
              "765            5      121             72             23      112  26.2   \n",
              "766            1      126             60              0        0  30.1   \n",
              "767            1       93             70             31        0  30.4   \n",
              "\n",
              "     DiabetesPedigreeFunction  Age  Outcome  \n",
              "758                     0.197   26        0  \n",
              "759                     0.278   66        1  \n",
              "760                     0.766   22        0  \n",
              "761                     0.403   43        1  \n",
              "762                     0.142   33        0  \n",
              "763                     0.171   63        0  \n",
              "764                     0.340   27        0  \n",
              "765                     0.245   30        0  \n",
              "766                     0.349   47        1  \n",
              "767                     0.315   23        0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e7e5d181-c669-4576-a0af-9a271da59746\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>758</th>\n",
              "      <td>1</td>\n",
              "      <td>106</td>\n",
              "      <td>76</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>37.5</td>\n",
              "      <td>0.197</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>759</th>\n",
              "      <td>6</td>\n",
              "      <td>190</td>\n",
              "      <td>92</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>35.5</td>\n",
              "      <td>0.278</td>\n",
              "      <td>66</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>760</th>\n",
              "      <td>2</td>\n",
              "      <td>88</td>\n",
              "      <td>58</td>\n",
              "      <td>26</td>\n",
              "      <td>16</td>\n",
              "      <td>28.4</td>\n",
              "      <td>0.766</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>761</th>\n",
              "      <td>9</td>\n",
              "      <td>170</td>\n",
              "      <td>74</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.403</td>\n",
              "      <td>43</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>762</th>\n",
              "      <td>9</td>\n",
              "      <td>89</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>22.5</td>\n",
              "      <td>0.142</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>10</td>\n",
              "      <td>101</td>\n",
              "      <td>76</td>\n",
              "      <td>48</td>\n",
              "      <td>180</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.171</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>2</td>\n",
              "      <td>122</td>\n",
              "      <td>70</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>0.340</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>5</td>\n",
              "      <td>121</td>\n",
              "      <td>72</td>\n",
              "      <td>23</td>\n",
              "      <td>112</td>\n",
              "      <td>26.2</td>\n",
              "      <td>0.245</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>1</td>\n",
              "      <td>126</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.349</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>1</td>\n",
              "      <td>93</td>\n",
              "      <td>70</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>30.4</td>\n",
              "      <td>0.315</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7e5d181-c669-4576-a0af-9a271da59746')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e7e5d181-c669-4576-a0af-9a271da59746 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e7e5d181-c669-4576-a0af-9a271da59746');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = data.values\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "print(X)\n",
        "print(Y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjnJgQ3URVq8",
        "outputId": "73a58442-b689-441a-835d-2c06c70b0258"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  6.    148.     72.    ...  33.6     0.627  50.   ]\n",
            " [  1.     85.     66.    ...  26.6     0.351  31.   ]\n",
            " [  8.    183.     64.    ...  23.3     0.672  32.   ]\n",
            " ...\n",
            " [  5.    121.     72.    ...  26.2     0.245  30.   ]\n",
            " [  1.    126.     60.    ...  30.1     0.349  47.   ]\n",
            " [  1.     93.     70.    ...  30.4     0.315  23.   ]]\n",
            "[1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.\n",
            " 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
            " 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1.\n",
            " 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0.\n",
            " 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
            " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1.\n",
            " 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X_scale = min_max_scaler.fit_transform(X)\n",
        "X_scale"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YRkVu3vSNk4",
        "outputId": "bec0d62b-015d-444f-9071-546c3dd66ebd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.35294118, 0.74371859, 0.59016393, ..., 0.50074516, 0.23441503,\n",
              "        0.48333333],\n",
              "       [0.05882353, 0.42713568, 0.54098361, ..., 0.39642325, 0.11656704,\n",
              "        0.16666667],\n",
              "       [0.47058824, 0.91959799, 0.52459016, ..., 0.34724292, 0.25362938,\n",
              "        0.18333333],\n",
              "       ...,\n",
              "       [0.29411765, 0.6080402 , 0.59016393, ..., 0.390462  , 0.07130658,\n",
              "        0.15      ],\n",
              "       [0.05882353, 0.63316583, 0.49180328, ..., 0.4485842 , 0.11571307,\n",
              "        0.43333333],\n",
              "       [0.05882353, 0.46733668, 0.57377049, ..., 0.45305514, 0.10119556,\n",
              "        0.03333333]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import np_utils\n",
        "encoded_y = np_utils.to_categorical(Y)\n",
        "encoded_y\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIcdGgA9San8",
        "outputId": "78bd501b-fe8b-4dfd-bea4-52e50304ca19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       ...,\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_training, X_testing, Y_training, Y_testing = train_test_split(X_scale, encoded_y, test_size=0.2, random_state=10)\n",
        "X_training, X_valid, Y_training, Y_valid = train_test_split(X_training, Y_training, test_size=0.2, random_state=10)\n",
        "print(len(X_training))\n",
        "print(len(X_testing))\n",
        "print(len(X_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZisPqJ8Slkj",
        "outputId": "a7ee77b6-670d-4965-8575-4c720acaa2be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "491\n",
            "154\n",
            "123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "metadata": {
        "id": "q1BwcUfHS4gC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(24, input_shape=(8,), activation='relu'))\n",
        "model.add(Dense(20, activation='relu'))\n",
        "model.add(Dense(12, activation='tanh'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.summary()   #gives a summary of the model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgZvvG9_TJxA",
        "outputId": "9588901e-0e91-4c3d-c50a-4351af1b406c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 24)                216       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 20)                500       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 12)                252       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 8)                 104       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,090\n",
            "Trainable params: 1,090\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import optimizers\n",
        "opt=optimizers.SGD(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "#model training\n",
        "hist = model.fit(X_training, Y_training,batch_size=4,  epochs=750, validation_data=(X_valid,Y_valid))\n",
        "# if you have 1000 training examples, and your batch size is 500, then it will take 2 iterations to complete 1 epoch.\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsMJev7ZUGQA",
        "outputId": "b603dff4-12e2-4836-c7a1-0fadcef05328"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/750\n",
            "123/123 [==============================] - 1s 3ms/step - loss: 0.2750 - accuracy: 0.8839 - val_loss: 0.6851 - val_accuracy: 0.7724\n",
            "Epoch 2/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2802 - accuracy: 0.8635 - val_loss: 0.7023 - val_accuracy: 0.7642\n",
            "Epoch 3/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2770 - accuracy: 0.8921 - val_loss: 0.7439 - val_accuracy: 0.7317\n",
            "Epoch 4/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2723 - accuracy: 0.8798 - val_loss: 0.7376 - val_accuracy: 0.7398\n",
            "Epoch 5/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2795 - accuracy: 0.8717 - val_loss: 0.6744 - val_accuracy: 0.7561\n",
            "Epoch 6/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2765 - accuracy: 0.8819 - val_loss: 0.6967 - val_accuracy: 0.7642\n",
            "Epoch 7/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2897 - accuracy: 0.8697 - val_loss: 0.8051 - val_accuracy: 0.7154\n",
            "Epoch 8/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2661 - accuracy: 0.8859 - val_loss: 0.7746 - val_accuracy: 0.7724\n",
            "Epoch 9/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2810 - accuracy: 0.8798 - val_loss: 0.7279 - val_accuracy: 0.7967\n",
            "Epoch 10/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2711 - accuracy: 0.8676 - val_loss: 0.7777 - val_accuracy: 0.7154\n",
            "Epoch 11/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2681 - accuracy: 0.8778 - val_loss: 0.6874 - val_accuracy: 0.7561\n",
            "Epoch 12/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2728 - accuracy: 0.8798 - val_loss: 0.6658 - val_accuracy: 0.7886\n",
            "Epoch 13/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2746 - accuracy: 0.8900 - val_loss: 0.7999 - val_accuracy: 0.7642\n",
            "Epoch 14/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2773 - accuracy: 0.8819 - val_loss: 0.7330 - val_accuracy: 0.7642\n",
            "Epoch 15/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2704 - accuracy: 0.9043 - val_loss: 0.7221 - val_accuracy: 0.7236\n",
            "Epoch 16/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2686 - accuracy: 0.8982 - val_loss: 0.7246 - val_accuracy: 0.7642\n",
            "Epoch 17/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2520 - accuracy: 0.8880 - val_loss: 0.7064 - val_accuracy: 0.7886\n",
            "Epoch 18/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2701 - accuracy: 0.8859 - val_loss: 0.7230 - val_accuracy: 0.7642\n",
            "Epoch 19/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2806 - accuracy: 0.8758 - val_loss: 0.7741 - val_accuracy: 0.7724\n",
            "Epoch 20/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2646 - accuracy: 0.8839 - val_loss: 0.7193 - val_accuracy: 0.7886\n",
            "Epoch 21/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2717 - accuracy: 0.8900 - val_loss: 0.7419 - val_accuracy: 0.7886\n",
            "Epoch 22/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2559 - accuracy: 0.8900 - val_loss: 0.8758 - val_accuracy: 0.7073\n",
            "Epoch 23/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2876 - accuracy: 0.8656 - val_loss: 0.7086 - val_accuracy: 0.7480\n",
            "Epoch 24/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2581 - accuracy: 0.8778 - val_loss: 0.7098 - val_accuracy: 0.7561\n",
            "Epoch 25/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2532 - accuracy: 0.8880 - val_loss: 0.7847 - val_accuracy: 0.7724\n",
            "Epoch 26/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2640 - accuracy: 0.8880 - val_loss: 0.7256 - val_accuracy: 0.7561\n",
            "Epoch 27/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2483 - accuracy: 0.8961 - val_loss: 0.8081 - val_accuracy: 0.7642\n",
            "Epoch 28/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2514 - accuracy: 0.8880 - val_loss: 0.7469 - val_accuracy: 0.7642\n",
            "Epoch 29/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2692 - accuracy: 0.8859 - val_loss: 0.7302 - val_accuracy: 0.7642\n",
            "Epoch 30/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2540 - accuracy: 0.8798 - val_loss: 0.7657 - val_accuracy: 0.7805\n",
            "Epoch 31/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2645 - accuracy: 0.8839 - val_loss: 0.7413 - val_accuracy: 0.7561\n",
            "Epoch 32/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2732 - accuracy: 0.8819 - val_loss: 0.7415 - val_accuracy: 0.7480\n",
            "Epoch 33/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2474 - accuracy: 0.9124 - val_loss: 0.7583 - val_accuracy: 0.7561\n",
            "Epoch 34/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2613 - accuracy: 0.8778 - val_loss: 0.8383 - val_accuracy: 0.7561\n",
            "Epoch 35/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2618 - accuracy: 0.8921 - val_loss: 0.8373 - val_accuracy: 0.7642\n",
            "Epoch 36/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2878 - accuracy: 0.8737 - val_loss: 0.8422 - val_accuracy: 0.7642\n",
            "Epoch 37/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2750 - accuracy: 0.8839 - val_loss: 0.7363 - val_accuracy: 0.7642\n",
            "Epoch 38/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2490 - accuracy: 0.8921 - val_loss: 0.7328 - val_accuracy: 0.7724\n",
            "Epoch 39/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.9002 - val_loss: 0.7533 - val_accuracy: 0.7642\n",
            "Epoch 40/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.8880 - val_loss: 0.7324 - val_accuracy: 0.7642\n",
            "Epoch 41/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2538 - accuracy: 0.8900 - val_loss: 0.7348 - val_accuracy: 0.7805\n",
            "Epoch 42/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2661 - accuracy: 0.8798 - val_loss: 0.7583 - val_accuracy: 0.7480\n",
            "Epoch 43/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2498 - accuracy: 0.8941 - val_loss: 0.7476 - val_accuracy: 0.7561\n",
            "Epoch 44/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2561 - accuracy: 0.8737 - val_loss: 0.7784 - val_accuracy: 0.7805\n",
            "Epoch 45/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2557 - accuracy: 0.8880 - val_loss: 0.7452 - val_accuracy: 0.7724\n",
            "Epoch 46/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2408 - accuracy: 0.9002 - val_loss: 0.8862 - val_accuracy: 0.7724\n",
            "Epoch 47/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2551 - accuracy: 0.8982 - val_loss: 0.6986 - val_accuracy: 0.7886\n",
            "Epoch 48/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2704 - accuracy: 0.8839 - val_loss: 0.7622 - val_accuracy: 0.7642\n",
            "Epoch 49/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2479 - accuracy: 0.8839 - val_loss: 0.8047 - val_accuracy: 0.7642\n",
            "Epoch 50/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.8961 - val_loss: 0.7984 - val_accuracy: 0.7398\n",
            "Epoch 51/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2677 - accuracy: 0.8819 - val_loss: 0.7283 - val_accuracy: 0.7886\n",
            "Epoch 52/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2388 - accuracy: 0.8921 - val_loss: 0.8082 - val_accuracy: 0.7317\n",
            "Epoch 53/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2477 - accuracy: 0.9002 - val_loss: 0.7958 - val_accuracy: 0.7236\n",
            "Epoch 54/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2526 - accuracy: 0.8921 - val_loss: 0.7735 - val_accuracy: 0.7805\n",
            "Epoch 55/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2571 - accuracy: 0.8839 - val_loss: 0.7770 - val_accuracy: 0.7805\n",
            "Epoch 56/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2371 - accuracy: 0.8961 - val_loss: 0.7171 - val_accuracy: 0.7967\n",
            "Epoch 57/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.8819 - val_loss: 0.7713 - val_accuracy: 0.7642\n",
            "Epoch 58/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2413 - accuracy: 0.9022 - val_loss: 0.7819 - val_accuracy: 0.7398\n",
            "Epoch 59/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2385 - accuracy: 0.9043 - val_loss: 0.8045 - val_accuracy: 0.7724\n",
            "Epoch 60/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2368 - accuracy: 0.9022 - val_loss: 0.7962 - val_accuracy: 0.7480\n",
            "Epoch 61/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2484 - accuracy: 0.8921 - val_loss: 0.8691 - val_accuracy: 0.7480\n",
            "Epoch 62/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2654 - accuracy: 0.8737 - val_loss: 0.8970 - val_accuracy: 0.7561\n",
            "Epoch 63/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2429 - accuracy: 0.8859 - val_loss: 0.8577 - val_accuracy: 0.7561\n",
            "Epoch 64/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2350 - accuracy: 0.8900 - val_loss: 0.7516 - val_accuracy: 0.7805\n",
            "Epoch 65/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2329 - accuracy: 0.9084 - val_loss: 0.8126 - val_accuracy: 0.7886\n",
            "Epoch 66/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2527 - accuracy: 0.9043 - val_loss: 0.8629 - val_accuracy: 0.7561\n",
            "Epoch 67/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2511 - accuracy: 0.8798 - val_loss: 0.8072 - val_accuracy: 0.7561\n",
            "Epoch 68/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2374 - accuracy: 0.9002 - val_loss: 0.8427 - val_accuracy: 0.7805\n",
            "Epoch 69/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2374 - accuracy: 0.8982 - val_loss: 0.8554 - val_accuracy: 0.7398\n",
            "Epoch 70/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2600 - accuracy: 0.8941 - val_loss: 0.8368 - val_accuracy: 0.7724\n",
            "Epoch 71/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2471 - accuracy: 0.8941 - val_loss: 0.8787 - val_accuracy: 0.7642\n",
            "Epoch 72/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2358 - accuracy: 0.9002 - val_loss: 0.8220 - val_accuracy: 0.7317\n",
            "Epoch 73/750\n",
            "123/123 [==============================] - 0s 4ms/step - loss: 0.2410 - accuracy: 0.9084 - val_loss: 0.8231 - val_accuracy: 0.7561\n",
            "Epoch 74/750\n",
            "123/123 [==============================] - 1s 5ms/step - loss: 0.2863 - accuracy: 0.8900 - val_loss: 0.8073 - val_accuracy: 0.7480\n",
            "Epoch 75/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2419 - accuracy: 0.9002 - val_loss: 0.8818 - val_accuracy: 0.7561\n",
            "Epoch 76/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2422 - accuracy: 0.9022 - val_loss: 0.8023 - val_accuracy: 0.7642\n",
            "Epoch 77/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2587 - accuracy: 0.8839 - val_loss: 0.7574 - val_accuracy: 0.7967\n",
            "Epoch 78/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2544 - accuracy: 0.8880 - val_loss: 0.7854 - val_accuracy: 0.7480\n",
            "Epoch 79/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2361 - accuracy: 0.8982 - val_loss: 0.9164 - val_accuracy: 0.7236\n",
            "Epoch 80/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2473 - accuracy: 0.9063 - val_loss: 0.8336 - val_accuracy: 0.7886\n",
            "Epoch 81/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2421 - accuracy: 0.8941 - val_loss: 0.8317 - val_accuracy: 0.7642\n",
            "Epoch 82/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.9002 - val_loss: 0.8910 - val_accuracy: 0.7317\n",
            "Epoch 83/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2538 - accuracy: 0.8880 - val_loss: 0.8449 - val_accuracy: 0.7561\n",
            "Epoch 84/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2275 - accuracy: 0.9002 - val_loss: 0.9079 - val_accuracy: 0.7724\n",
            "Epoch 85/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2365 - accuracy: 0.8982 - val_loss: 0.8386 - val_accuracy: 0.7724\n",
            "Epoch 86/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2307 - accuracy: 0.9063 - val_loss: 0.8594 - val_accuracy: 0.7886\n",
            "Epoch 87/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2418 - accuracy: 0.9022 - val_loss: 0.8726 - val_accuracy: 0.7236\n",
            "Epoch 88/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2433 - accuracy: 0.8921 - val_loss: 0.9075 - val_accuracy: 0.7236\n",
            "Epoch 89/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2295 - accuracy: 0.9043 - val_loss: 0.8492 - val_accuracy: 0.7561\n",
            "Epoch 90/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2547 - accuracy: 0.8758 - val_loss: 0.8288 - val_accuracy: 0.7805\n",
            "Epoch 91/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2361 - accuracy: 0.9002 - val_loss: 0.7938 - val_accuracy: 0.7561\n",
            "Epoch 92/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2190 - accuracy: 0.9063 - val_loss: 0.9315 - val_accuracy: 0.7398\n",
            "Epoch 93/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2321 - accuracy: 0.8941 - val_loss: 0.8615 - val_accuracy: 0.7642\n",
            "Epoch 94/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2500 - accuracy: 0.8880 - val_loss: 0.9230 - val_accuracy: 0.7480\n",
            "Epoch 95/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.8921 - val_loss: 0.9784 - val_accuracy: 0.7154\n",
            "Epoch 96/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2349 - accuracy: 0.8961 - val_loss: 0.8316 - val_accuracy: 0.7642\n",
            "Epoch 97/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2341 - accuracy: 0.9043 - val_loss: 0.9408 - val_accuracy: 0.7561\n",
            "Epoch 98/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2221 - accuracy: 0.9084 - val_loss: 0.8805 - val_accuracy: 0.7480\n",
            "Epoch 99/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2296 - accuracy: 0.9063 - val_loss: 0.8064 - val_accuracy: 0.7805\n",
            "Epoch 100/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2379 - accuracy: 0.8941 - val_loss: 0.8381 - val_accuracy: 0.7805\n",
            "Epoch 101/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2373 - accuracy: 0.8961 - val_loss: 0.9913 - val_accuracy: 0.7317\n",
            "Epoch 102/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2372 - accuracy: 0.9043 - val_loss: 0.9010 - val_accuracy: 0.7317\n",
            "Epoch 103/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2422 - accuracy: 0.9002 - val_loss: 0.8293 - val_accuracy: 0.7886\n",
            "Epoch 104/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2029 - accuracy: 0.9287 - val_loss: 0.9722 - val_accuracy: 0.7398\n",
            "Epoch 105/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2067 - accuracy: 0.9124 - val_loss: 0.8917 - val_accuracy: 0.7398\n",
            "Epoch 106/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2169 - accuracy: 0.9206 - val_loss: 0.9967 - val_accuracy: 0.7561\n",
            "Epoch 107/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2224 - accuracy: 0.9022 - val_loss: 0.9261 - val_accuracy: 0.7480\n",
            "Epoch 108/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2489 - accuracy: 0.8961 - val_loss: 0.8835 - val_accuracy: 0.7805\n",
            "Epoch 109/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2593 - accuracy: 0.9145 - val_loss: 0.9725 - val_accuracy: 0.7805\n",
            "Epoch 110/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2088 - accuracy: 0.9104 - val_loss: 0.9023 - val_accuracy: 0.7480\n",
            "Epoch 111/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2382 - accuracy: 0.8941 - val_loss: 0.8637 - val_accuracy: 0.7805\n",
            "Epoch 112/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2175 - accuracy: 0.9063 - val_loss: 0.8464 - val_accuracy: 0.7724\n",
            "Epoch 113/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2249 - accuracy: 0.9063 - val_loss: 0.9103 - val_accuracy: 0.7805\n",
            "Epoch 114/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8941 - val_loss: 0.8603 - val_accuracy: 0.7724\n",
            "Epoch 115/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2171 - accuracy: 0.8982 - val_loss: 0.8543 - val_accuracy: 0.7398\n",
            "Epoch 116/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2386 - accuracy: 0.9043 - val_loss: 0.8602 - val_accuracy: 0.7886\n",
            "Epoch 117/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2201 - accuracy: 0.9104 - val_loss: 0.9114 - val_accuracy: 0.7561\n",
            "Epoch 118/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2064 - accuracy: 0.9124 - val_loss: 0.9730 - val_accuracy: 0.7561\n",
            "Epoch 119/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2308 - accuracy: 0.9043 - val_loss: 0.8568 - val_accuracy: 0.7805\n",
            "Epoch 120/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2158 - accuracy: 0.9124 - val_loss: 0.9243 - val_accuracy: 0.7561\n",
            "Epoch 121/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2170 - accuracy: 0.9002 - val_loss: 0.8279 - val_accuracy: 0.7967\n",
            "Epoch 122/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2180 - accuracy: 0.9043 - val_loss: 0.9291 - val_accuracy: 0.7480\n",
            "Epoch 123/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2135 - accuracy: 0.9124 - val_loss: 1.0828 - val_accuracy: 0.7561\n",
            "Epoch 124/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2719 - accuracy: 0.8961 - val_loss: 0.8468 - val_accuracy: 0.7805\n",
            "Epoch 125/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2185 - accuracy: 0.9063 - val_loss: 0.9590 - val_accuracy: 0.7805\n",
            "Epoch 126/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2422 - accuracy: 0.9022 - val_loss: 0.9383 - val_accuracy: 0.7317\n",
            "Epoch 127/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2261 - accuracy: 0.9022 - val_loss: 0.9609 - val_accuracy: 0.7724\n",
            "Epoch 128/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2304 - accuracy: 0.9022 - val_loss: 0.9092 - val_accuracy: 0.7724\n",
            "Epoch 129/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2072 - accuracy: 0.9104 - val_loss: 0.8510 - val_accuracy: 0.7561\n",
            "Epoch 130/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2096 - accuracy: 0.9165 - val_loss: 0.8897 - val_accuracy: 0.7805\n",
            "Epoch 131/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2224 - accuracy: 0.9084 - val_loss: 0.9026 - val_accuracy: 0.7805\n",
            "Epoch 132/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2046 - accuracy: 0.9022 - val_loss: 0.9911 - val_accuracy: 0.7642\n",
            "Epoch 133/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2031 - accuracy: 0.9104 - val_loss: 0.9537 - val_accuracy: 0.7886\n",
            "Epoch 134/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2163 - accuracy: 0.9084 - val_loss: 1.0037 - val_accuracy: 0.7317\n",
            "Epoch 135/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2181 - accuracy: 0.9043 - val_loss: 0.9030 - val_accuracy: 0.7805\n",
            "Epoch 136/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1986 - accuracy: 0.9104 - val_loss: 0.9375 - val_accuracy: 0.7398\n",
            "Epoch 137/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2066 - accuracy: 0.9084 - val_loss: 0.9400 - val_accuracy: 0.7805\n",
            "Epoch 138/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2057 - accuracy: 0.9063 - val_loss: 0.9517 - val_accuracy: 0.7886\n",
            "Epoch 139/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2147 - accuracy: 0.9084 - val_loss: 0.8918 - val_accuracy: 0.7805\n",
            "Epoch 140/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2582 - accuracy: 0.8819 - val_loss: 0.9675 - val_accuracy: 0.7236\n",
            "Epoch 141/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1918 - accuracy: 0.9145 - val_loss: 0.9975 - val_accuracy: 0.7236\n",
            "Epoch 142/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2371 - accuracy: 0.8961 - val_loss: 1.0381 - val_accuracy: 0.7398\n",
            "Epoch 143/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2359 - accuracy: 0.8982 - val_loss: 0.9806 - val_accuracy: 0.7480\n",
            "Epoch 144/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2157 - accuracy: 0.9165 - val_loss: 0.8726 - val_accuracy: 0.7967\n",
            "Epoch 145/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2039 - accuracy: 0.9145 - val_loss: 1.0002 - val_accuracy: 0.7724\n",
            "Epoch 146/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2312 - accuracy: 0.9084 - val_loss: 1.0345 - val_accuracy: 0.7317\n",
            "Epoch 147/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2521 - accuracy: 0.9084 - val_loss: 0.9513 - val_accuracy: 0.7642\n",
            "Epoch 148/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1916 - accuracy: 0.9246 - val_loss: 1.0311 - val_accuracy: 0.7724\n",
            "Epoch 149/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2001 - accuracy: 0.9246 - val_loss: 0.9383 - val_accuracy: 0.7398\n",
            "Epoch 150/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1882 - accuracy: 0.9267 - val_loss: 1.0225 - val_accuracy: 0.7154\n",
            "Epoch 151/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2029 - accuracy: 0.8900 - val_loss: 0.9662 - val_accuracy: 0.7561\n",
            "Epoch 152/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2009 - accuracy: 0.9165 - val_loss: 0.9196 - val_accuracy: 0.7886\n",
            "Epoch 153/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2124 - accuracy: 0.9084 - val_loss: 0.9170 - val_accuracy: 0.7886\n",
            "Epoch 154/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2146 - accuracy: 0.9043 - val_loss: 1.1542 - val_accuracy: 0.7154\n",
            "Epoch 155/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2220 - accuracy: 0.9063 - val_loss: 1.0146 - val_accuracy: 0.7724\n",
            "Epoch 156/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1961 - accuracy: 0.9206 - val_loss: 0.8818 - val_accuracy: 0.7805\n",
            "Epoch 157/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2010 - accuracy: 0.9206 - val_loss: 0.9888 - val_accuracy: 0.7480\n",
            "Epoch 158/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1900 - accuracy: 0.9226 - val_loss: 0.9783 - val_accuracy: 0.7480\n",
            "Epoch 159/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2278 - accuracy: 0.8921 - val_loss: 0.9532 - val_accuracy: 0.7642\n",
            "Epoch 160/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1955 - accuracy: 0.9185 - val_loss: 0.9678 - val_accuracy: 0.7642\n",
            "Epoch 161/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1890 - accuracy: 0.9185 - val_loss: 0.9614 - val_accuracy: 0.7886\n",
            "Epoch 162/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1983 - accuracy: 0.9165 - val_loss: 0.9361 - val_accuracy: 0.7805\n",
            "Epoch 163/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2123 - accuracy: 0.9124 - val_loss: 0.9823 - val_accuracy: 0.7886\n",
            "Epoch 164/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1826 - accuracy: 0.9226 - val_loss: 0.9441 - val_accuracy: 0.7642\n",
            "Epoch 165/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2179 - accuracy: 0.9022 - val_loss: 0.9460 - val_accuracy: 0.7805\n",
            "Epoch 166/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1975 - accuracy: 0.9084 - val_loss: 0.9653 - val_accuracy: 0.7642\n",
            "Epoch 167/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1892 - accuracy: 0.9246 - val_loss: 1.0468 - val_accuracy: 0.7642\n",
            "Epoch 168/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1927 - accuracy: 0.9246 - val_loss: 1.0261 - val_accuracy: 0.7642\n",
            "Epoch 169/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1798 - accuracy: 0.9308 - val_loss: 1.0964 - val_accuracy: 0.7317\n",
            "Epoch 170/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2367 - accuracy: 0.9104 - val_loss: 0.8830 - val_accuracy: 0.7967\n",
            "Epoch 171/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1829 - accuracy: 0.9145 - val_loss: 0.9665 - val_accuracy: 0.7398\n",
            "Epoch 172/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2535 - accuracy: 0.9002 - val_loss: 0.9141 - val_accuracy: 0.7642\n",
            "Epoch 173/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1870 - accuracy: 0.9287 - val_loss: 0.9688 - val_accuracy: 0.7480\n",
            "Epoch 174/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1832 - accuracy: 0.9267 - val_loss: 1.0144 - val_accuracy: 0.7805\n",
            "Epoch 175/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2175 - accuracy: 0.9002 - val_loss: 1.0448 - val_accuracy: 0.7480\n",
            "Epoch 176/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2259 - accuracy: 0.9043 - val_loss: 1.0132 - val_accuracy: 0.7480\n",
            "Epoch 177/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2008 - accuracy: 0.9185 - val_loss: 0.8738 - val_accuracy: 0.7642\n",
            "Epoch 178/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2387 - accuracy: 0.8880 - val_loss: 1.0551 - val_accuracy: 0.7398\n",
            "Epoch 179/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2030 - accuracy: 0.9104 - val_loss: 1.0982 - val_accuracy: 0.7236\n",
            "Epoch 180/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1947 - accuracy: 0.9206 - val_loss: 0.9435 - val_accuracy: 0.7724\n",
            "Epoch 181/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1947 - accuracy: 0.9104 - val_loss: 1.0831 - val_accuracy: 0.7480\n",
            "Epoch 182/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1805 - accuracy: 0.9246 - val_loss: 1.0318 - val_accuracy: 0.7724\n",
            "Epoch 183/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1938 - accuracy: 0.9165 - val_loss: 1.0056 - val_accuracy: 0.7398\n",
            "Epoch 184/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2321 - accuracy: 0.9124 - val_loss: 1.1191 - val_accuracy: 0.7480\n",
            "Epoch 185/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1919 - accuracy: 0.9206 - val_loss: 1.1407 - val_accuracy: 0.7236\n",
            "Epoch 186/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1937 - accuracy: 0.9185 - val_loss: 0.9672 - val_accuracy: 0.7561\n",
            "Epoch 187/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1924 - accuracy: 0.9185 - val_loss: 1.0018 - val_accuracy: 0.7642\n",
            "Epoch 188/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1731 - accuracy: 0.9246 - val_loss: 1.0882 - val_accuracy: 0.7317\n",
            "Epoch 189/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1814 - accuracy: 0.9145 - val_loss: 1.0107 - val_accuracy: 0.7642\n",
            "Epoch 190/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1745 - accuracy: 0.9328 - val_loss: 1.1166 - val_accuracy: 0.7724\n",
            "Epoch 191/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1797 - accuracy: 0.9226 - val_loss: 0.9856 - val_accuracy: 0.7317\n",
            "Epoch 192/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1874 - accuracy: 0.9165 - val_loss: 1.0308 - val_accuracy: 0.7561\n",
            "Epoch 193/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1920 - accuracy: 0.9124 - val_loss: 1.0290 - val_accuracy: 0.7236\n",
            "Epoch 194/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1863 - accuracy: 0.9328 - val_loss: 1.0266 - val_accuracy: 0.7317\n",
            "Epoch 195/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1800 - accuracy: 0.9267 - val_loss: 1.0358 - val_accuracy: 0.7886\n",
            "Epoch 196/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2059 - accuracy: 0.9145 - val_loss: 1.0454 - val_accuracy: 0.7805\n",
            "Epoch 197/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1906 - accuracy: 0.9206 - val_loss: 1.0270 - val_accuracy: 0.7886\n",
            "Epoch 198/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2157 - accuracy: 0.9246 - val_loss: 1.1255 - val_accuracy: 0.7886\n",
            "Epoch 199/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1888 - accuracy: 0.9124 - val_loss: 1.0719 - val_accuracy: 0.7642\n",
            "Epoch 200/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1844 - accuracy: 0.9185 - val_loss: 1.1500 - val_accuracy: 0.7642\n",
            "Epoch 201/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.9246 - val_loss: 1.1184 - val_accuracy: 0.7724\n",
            "Epoch 202/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1766 - accuracy: 0.9165 - val_loss: 1.1168 - val_accuracy: 0.7805\n",
            "Epoch 203/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1730 - accuracy: 0.9267 - val_loss: 1.0322 - val_accuracy: 0.7398\n",
            "Epoch 204/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1957 - accuracy: 0.9124 - val_loss: 1.1422 - val_accuracy: 0.7724\n",
            "Epoch 205/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1738 - accuracy: 0.9308 - val_loss: 1.1166 - val_accuracy: 0.7398\n",
            "Epoch 206/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1750 - accuracy: 0.9206 - val_loss: 1.1365 - val_accuracy: 0.7805\n",
            "Epoch 207/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2242 - accuracy: 0.9084 - val_loss: 1.0531 - val_accuracy: 0.7398\n",
            "Epoch 208/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2087 - accuracy: 0.9124 - val_loss: 1.0214 - val_accuracy: 0.7805\n",
            "Epoch 209/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1781 - accuracy: 0.9226 - val_loss: 1.1025 - val_accuracy: 0.7480\n",
            "Epoch 210/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1987 - accuracy: 0.9165 - val_loss: 1.3314 - val_accuracy: 0.7398\n",
            "Epoch 211/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1751 - accuracy: 0.9369 - val_loss: 1.0536 - val_accuracy: 0.7724\n",
            "Epoch 212/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2104 - accuracy: 0.9185 - val_loss: 1.2275 - val_accuracy: 0.7154\n",
            "Epoch 213/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1560 - accuracy: 0.9430 - val_loss: 0.9972 - val_accuracy: 0.7724\n",
            "Epoch 214/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2155 - accuracy: 0.9226 - val_loss: 1.0874 - val_accuracy: 0.7642\n",
            "Epoch 215/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1425 - accuracy: 0.9470 - val_loss: 1.1266 - val_accuracy: 0.7724\n",
            "Epoch 216/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1670 - accuracy: 0.9287 - val_loss: 1.0708 - val_accuracy: 0.7561\n",
            "Epoch 217/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1645 - accuracy: 0.9328 - val_loss: 1.0861 - val_accuracy: 0.7642\n",
            "Epoch 218/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1676 - accuracy: 0.9409 - val_loss: 1.1623 - val_accuracy: 0.7480\n",
            "Epoch 219/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1637 - accuracy: 0.9246 - val_loss: 1.2396 - val_accuracy: 0.7154\n",
            "Epoch 220/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1744 - accuracy: 0.9287 - val_loss: 1.1863 - val_accuracy: 0.7398\n",
            "Epoch 221/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1963 - accuracy: 0.9145 - val_loss: 1.0749 - val_accuracy: 0.7480\n",
            "Epoch 222/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1706 - accuracy: 0.9348 - val_loss: 1.0892 - val_accuracy: 0.7642\n",
            "Epoch 223/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1575 - accuracy: 0.9328 - val_loss: 1.1911 - val_accuracy: 0.7561\n",
            "Epoch 224/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1773 - accuracy: 0.9206 - val_loss: 1.1321 - val_accuracy: 0.7724\n",
            "Epoch 225/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1858 - accuracy: 0.9226 - val_loss: 1.0058 - val_accuracy: 0.7724\n",
            "Epoch 226/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2037 - accuracy: 0.9145 - val_loss: 1.0972 - val_accuracy: 0.7967\n",
            "Epoch 227/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2208 - accuracy: 0.9104 - val_loss: 1.0011 - val_accuracy: 0.7642\n",
            "Epoch 228/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1628 - accuracy: 0.9369 - val_loss: 1.0690 - val_accuracy: 0.7724\n",
            "Epoch 229/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1693 - accuracy: 0.9348 - val_loss: 1.1236 - val_accuracy: 0.7642\n",
            "Epoch 230/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1820 - accuracy: 0.9287 - val_loss: 0.9844 - val_accuracy: 0.7398\n",
            "Epoch 231/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1548 - accuracy: 0.9409 - val_loss: 1.1461 - val_accuracy: 0.7561\n",
            "Epoch 232/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1606 - accuracy: 0.9389 - val_loss: 1.1246 - val_accuracy: 0.7642\n",
            "Epoch 233/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1756 - accuracy: 0.9246 - val_loss: 1.1589 - val_accuracy: 0.7480\n",
            "Epoch 234/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1843 - accuracy: 0.9185 - val_loss: 1.2508 - val_accuracy: 0.7236\n",
            "Epoch 235/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2014 - accuracy: 0.9206 - val_loss: 1.1450 - val_accuracy: 0.7398\n",
            "Epoch 236/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1729 - accuracy: 0.9267 - val_loss: 1.0808 - val_accuracy: 0.7561\n",
            "Epoch 237/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2203 - accuracy: 0.9002 - val_loss: 1.0854 - val_accuracy: 0.7886\n",
            "Epoch 238/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1797 - accuracy: 0.9185 - val_loss: 1.1141 - val_accuracy: 0.7073\n",
            "Epoch 239/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2740 - accuracy: 0.8961 - val_loss: 1.0347 - val_accuracy: 0.7236\n",
            "Epoch 240/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1661 - accuracy: 0.9287 - val_loss: 1.1057 - val_accuracy: 0.7480\n",
            "Epoch 241/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1675 - accuracy: 0.9287 - val_loss: 1.1723 - val_accuracy: 0.7398\n",
            "Epoch 242/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1561 - accuracy: 0.9348 - val_loss: 1.1119 - val_accuracy: 0.7886\n",
            "Epoch 243/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1637 - accuracy: 0.9348 - val_loss: 1.0590 - val_accuracy: 0.7642\n",
            "Epoch 244/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1630 - accuracy: 0.9328 - val_loss: 1.1891 - val_accuracy: 0.7886\n",
            "Epoch 245/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1533 - accuracy: 0.9369 - val_loss: 1.0731 - val_accuracy: 0.7561\n",
            "Epoch 246/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1716 - accuracy: 0.9369 - val_loss: 1.1071 - val_accuracy: 0.7398\n",
            "Epoch 247/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1658 - accuracy: 0.9348 - val_loss: 1.0715 - val_accuracy: 0.7642\n",
            "Epoch 248/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1591 - accuracy: 0.9308 - val_loss: 1.1918 - val_accuracy: 0.7724\n",
            "Epoch 249/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2320 - accuracy: 0.9145 - val_loss: 1.0869 - val_accuracy: 0.7642\n",
            "Epoch 250/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1999 - accuracy: 0.9165 - val_loss: 1.1436 - val_accuracy: 0.7480\n",
            "Epoch 251/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1634 - accuracy: 0.9328 - val_loss: 1.2134 - val_accuracy: 0.7642\n",
            "Epoch 252/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1710 - accuracy: 0.9308 - val_loss: 1.1013 - val_accuracy: 0.7561\n",
            "Epoch 253/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3023 - accuracy: 0.8615 - val_loss: 1.1719 - val_accuracy: 0.7317\n",
            "Epoch 254/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1836 - accuracy: 0.9287 - val_loss: 1.0583 - val_accuracy: 0.7886\n",
            "Epoch 255/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.9287 - val_loss: 1.0485 - val_accuracy: 0.7805\n",
            "Epoch 256/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1525 - accuracy: 0.9430 - val_loss: 1.1681 - val_accuracy: 0.7724\n",
            "Epoch 257/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1479 - accuracy: 0.9328 - val_loss: 1.1435 - val_accuracy: 0.7642\n",
            "Epoch 258/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1591 - accuracy: 0.9246 - val_loss: 1.1878 - val_accuracy: 0.7398\n",
            "Epoch 259/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1585 - accuracy: 0.9348 - val_loss: 1.2075 - val_accuracy: 0.7398\n",
            "Epoch 260/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1484 - accuracy: 0.9450 - val_loss: 1.3116 - val_accuracy: 0.7398\n",
            "Epoch 261/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1478 - accuracy: 0.9389 - val_loss: 1.2860 - val_accuracy: 0.7236\n",
            "Epoch 262/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1657 - accuracy: 0.9409 - val_loss: 1.3766 - val_accuracy: 0.7805\n",
            "Epoch 263/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1468 - accuracy: 0.9470 - val_loss: 1.1789 - val_accuracy: 0.7724\n",
            "Epoch 264/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1476 - accuracy: 0.9369 - val_loss: 1.0686 - val_accuracy: 0.7561\n",
            "Epoch 265/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1897 - accuracy: 0.9246 - val_loss: 1.1718 - val_accuracy: 0.7154\n",
            "Epoch 266/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1382 - accuracy: 0.9532 - val_loss: 1.2071 - val_accuracy: 0.7724\n",
            "Epoch 267/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1405 - accuracy: 0.9491 - val_loss: 1.1275 - val_accuracy: 0.7398\n",
            "Epoch 268/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1499 - accuracy: 0.9389 - val_loss: 1.2285 - val_accuracy: 0.7480\n",
            "Epoch 269/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1837 - accuracy: 0.9246 - val_loss: 1.2091 - val_accuracy: 0.7561\n",
            "Epoch 270/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1677 - accuracy: 0.9267 - val_loss: 1.1548 - val_accuracy: 0.7724\n",
            "Epoch 271/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1436 - accuracy: 0.9409 - val_loss: 1.1433 - val_accuracy: 0.7398\n",
            "Epoch 272/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1303 - accuracy: 0.9532 - val_loss: 1.3384 - val_accuracy: 0.7398\n",
            "Epoch 273/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1447 - accuracy: 0.9389 - val_loss: 1.0898 - val_accuracy: 0.7398\n",
            "Epoch 274/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1527 - accuracy: 0.9430 - val_loss: 1.3828 - val_accuracy: 0.7317\n",
            "Epoch 275/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1253 - accuracy: 0.9532 - val_loss: 1.2377 - val_accuracy: 0.7642\n",
            "Epoch 276/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1929 - accuracy: 0.9369 - val_loss: 1.1373 - val_accuracy: 0.7154\n",
            "Epoch 277/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1384 - accuracy: 0.9491 - val_loss: 1.2375 - val_accuracy: 0.7398\n",
            "Epoch 278/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2185 - accuracy: 0.9043 - val_loss: 1.1258 - val_accuracy: 0.7561\n",
            "Epoch 279/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1811 - accuracy: 0.9287 - val_loss: 1.1939 - val_accuracy: 0.7398\n",
            "Epoch 280/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2123 - accuracy: 0.9185 - val_loss: 1.1319 - val_accuracy: 0.7642\n",
            "Epoch 281/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1678 - accuracy: 0.9308 - val_loss: 1.2853 - val_accuracy: 0.7561\n",
            "Epoch 282/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1637 - accuracy: 0.9369 - val_loss: 1.1990 - val_accuracy: 0.7480\n",
            "Epoch 283/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1437 - accuracy: 0.9450 - val_loss: 1.3171 - val_accuracy: 0.7317\n",
            "Epoch 284/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1482 - accuracy: 0.9470 - val_loss: 1.3662 - val_accuracy: 0.7398\n",
            "Epoch 285/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1711 - accuracy: 0.9308 - val_loss: 1.1710 - val_accuracy: 0.7398\n",
            "Epoch 286/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1381 - accuracy: 0.9409 - val_loss: 1.1715 - val_accuracy: 0.7642\n",
            "Epoch 287/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1612 - accuracy: 0.9328 - val_loss: 1.2000 - val_accuracy: 0.7642\n",
            "Epoch 288/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1282 - accuracy: 0.9511 - val_loss: 1.2574 - val_accuracy: 0.7561\n",
            "Epoch 289/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1513 - accuracy: 0.9369 - val_loss: 1.0763 - val_accuracy: 0.7480\n",
            "Epoch 290/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1378 - accuracy: 0.9409 - val_loss: 1.1438 - val_accuracy: 0.7724\n",
            "Epoch 291/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1657 - accuracy: 0.9328 - val_loss: 1.5630 - val_accuracy: 0.7236\n",
            "Epoch 292/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3201 - accuracy: 0.8798 - val_loss: 1.1554 - val_accuracy: 0.7561\n",
            "Epoch 293/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1733 - accuracy: 0.9246 - val_loss: 1.2532 - val_accuracy: 0.7073\n",
            "Epoch 294/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1411 - accuracy: 0.9491 - val_loss: 1.2481 - val_accuracy: 0.7480\n",
            "Epoch 295/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1400 - accuracy: 0.9430 - val_loss: 1.1840 - val_accuracy: 0.7236\n",
            "Epoch 296/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1400 - accuracy: 0.9450 - val_loss: 1.2671 - val_accuracy: 0.7317\n",
            "Epoch 297/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1521 - accuracy: 0.9450 - val_loss: 1.1340 - val_accuracy: 0.7561\n",
            "Epoch 298/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1243 - accuracy: 0.9532 - val_loss: 1.1714 - val_accuracy: 0.7236\n",
            "Epoch 299/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1498 - accuracy: 0.9409 - val_loss: 1.2197 - val_accuracy: 0.7642\n",
            "Epoch 300/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1411 - accuracy: 0.9511 - val_loss: 1.3348 - val_accuracy: 0.7724\n",
            "Epoch 301/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2561 - accuracy: 0.8941 - val_loss: 1.2098 - val_accuracy: 0.7561\n",
            "Epoch 302/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2079 - accuracy: 0.9226 - val_loss: 1.1556 - val_accuracy: 0.7642\n",
            "Epoch 303/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1840 - accuracy: 0.9165 - val_loss: 1.1222 - val_accuracy: 0.7724\n",
            "Epoch 304/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1455 - accuracy: 0.9369 - val_loss: 1.1791 - val_accuracy: 0.7561\n",
            "Epoch 305/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1653 - accuracy: 0.9287 - val_loss: 1.1494 - val_accuracy: 0.7724\n",
            "Epoch 306/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1366 - accuracy: 0.9389 - val_loss: 1.2743 - val_accuracy: 0.7724\n",
            "Epoch 307/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1420 - accuracy: 0.9491 - val_loss: 1.1921 - val_accuracy: 0.7480\n",
            "Epoch 308/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1956 - accuracy: 0.9226 - val_loss: 1.2229 - val_accuracy: 0.7561\n",
            "Epoch 309/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1586 - accuracy: 0.9430 - val_loss: 1.3128 - val_accuracy: 0.7480\n",
            "Epoch 310/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1448 - accuracy: 0.9470 - val_loss: 1.1912 - val_accuracy: 0.7561\n",
            "Epoch 311/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1219 - accuracy: 0.9511 - val_loss: 1.2429 - val_accuracy: 0.7724\n",
            "Epoch 312/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1487 - accuracy: 0.9409 - val_loss: 1.4058 - val_accuracy: 0.7480\n",
            "Epoch 313/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1483 - accuracy: 0.9308 - val_loss: 1.2207 - val_accuracy: 0.7480\n",
            "Epoch 314/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2268 - accuracy: 0.9104 - val_loss: 1.3255 - val_accuracy: 0.7317\n",
            "Epoch 315/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1361 - accuracy: 0.9409 - val_loss: 1.3242 - val_accuracy: 0.7236\n",
            "Epoch 316/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1537 - accuracy: 0.9430 - val_loss: 1.2218 - val_accuracy: 0.7398\n",
            "Epoch 317/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1362 - accuracy: 0.9511 - val_loss: 1.3606 - val_accuracy: 0.7317\n",
            "Epoch 318/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1079 - accuracy: 0.9552 - val_loss: 1.1904 - val_accuracy: 0.7561\n",
            "Epoch 319/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1483 - accuracy: 0.9328 - val_loss: 1.4035 - val_accuracy: 0.7317\n",
            "Epoch 320/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1225 - accuracy: 0.9572 - val_loss: 1.2291 - val_accuracy: 0.7805\n",
            "Epoch 321/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1310 - accuracy: 0.9450 - val_loss: 1.3660 - val_accuracy: 0.7398\n",
            "Epoch 322/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1309 - accuracy: 0.9511 - val_loss: 1.3483 - val_accuracy: 0.7398\n",
            "Epoch 323/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1993 - accuracy: 0.9206 - val_loss: 1.1021 - val_accuracy: 0.7561\n",
            "Epoch 324/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1531 - accuracy: 0.9328 - val_loss: 1.1295 - val_accuracy: 0.7480\n",
            "Epoch 325/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1428 - accuracy: 0.9470 - val_loss: 1.2479 - val_accuracy: 0.7886\n",
            "Epoch 326/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.9063 - val_loss: 1.2560 - val_accuracy: 0.7480\n",
            "Epoch 327/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1797 - accuracy: 0.9226 - val_loss: 1.2292 - val_accuracy: 0.7642\n",
            "Epoch 328/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1251 - accuracy: 0.9532 - val_loss: 1.2723 - val_accuracy: 0.7561\n",
            "Epoch 329/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1455 - accuracy: 0.9328 - val_loss: 1.2367 - val_accuracy: 0.7561\n",
            "Epoch 330/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1310 - accuracy: 0.9430 - val_loss: 1.2271 - val_accuracy: 0.7724\n",
            "Epoch 331/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1560 - accuracy: 0.9430 - val_loss: 1.4035 - val_accuracy: 0.7561\n",
            "Epoch 332/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1407 - accuracy: 0.9409 - val_loss: 1.2826 - val_accuracy: 0.7724\n",
            "Epoch 333/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1333 - accuracy: 0.9511 - val_loss: 1.2464 - val_accuracy: 0.7480\n",
            "Epoch 334/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1287 - accuracy: 0.9450 - val_loss: 1.2257 - val_accuracy: 0.7642\n",
            "Epoch 335/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1209 - accuracy: 0.9593 - val_loss: 1.3556 - val_accuracy: 0.7561\n",
            "Epoch 336/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1857 - accuracy: 0.9287 - val_loss: 1.1919 - val_accuracy: 0.7236\n",
            "Epoch 337/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1159 - accuracy: 0.9572 - val_loss: 1.2116 - val_accuracy: 0.7561\n",
            "Epoch 338/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1154 - accuracy: 0.9511 - val_loss: 1.3355 - val_accuracy: 0.7317\n",
            "Epoch 339/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1896 - accuracy: 0.9287 - val_loss: 1.2886 - val_accuracy: 0.7561\n",
            "Epoch 340/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1696 - accuracy: 0.9328 - val_loss: 1.2368 - val_accuracy: 0.7317\n",
            "Epoch 341/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1709 - accuracy: 0.9389 - val_loss: 1.2747 - val_accuracy: 0.6992\n",
            "Epoch 342/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1150 - accuracy: 0.9674 - val_loss: 1.2908 - val_accuracy: 0.7886\n",
            "Epoch 343/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1129 - accuracy: 0.9552 - val_loss: 1.2381 - val_accuracy: 0.7724\n",
            "Epoch 344/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1145 - accuracy: 0.9572 - val_loss: 1.2722 - val_accuracy: 0.7480\n",
            "Epoch 345/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2108 - accuracy: 0.9145 - val_loss: 1.1694 - val_accuracy: 0.7561\n",
            "Epoch 346/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1754 - accuracy: 0.9430 - val_loss: 1.0989 - val_accuracy: 0.7967\n",
            "Epoch 347/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1389 - accuracy: 0.9470 - val_loss: 1.2300 - val_accuracy: 0.7642\n",
            "Epoch 348/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1636 - accuracy: 0.9389 - val_loss: 1.2728 - val_accuracy: 0.7886\n",
            "Epoch 349/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1820 - accuracy: 0.9165 - val_loss: 1.2678 - val_accuracy: 0.7642\n",
            "Epoch 350/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1320 - accuracy: 0.9491 - val_loss: 1.2490 - val_accuracy: 0.7642\n",
            "Epoch 351/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1232 - accuracy: 0.9450 - val_loss: 1.4066 - val_accuracy: 0.7398\n",
            "Epoch 352/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2393 - accuracy: 0.9104 - val_loss: 1.2780 - val_accuracy: 0.7805\n",
            "Epoch 353/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1319 - accuracy: 0.9511 - val_loss: 1.3579 - val_accuracy: 0.7317\n",
            "Epoch 354/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1366 - accuracy: 0.9511 - val_loss: 1.2546 - val_accuracy: 0.7724\n",
            "Epoch 355/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1332 - accuracy: 0.9532 - val_loss: 1.3407 - val_accuracy: 0.7724\n",
            "Epoch 356/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1114 - accuracy: 0.9572 - val_loss: 1.3373 - val_accuracy: 0.7236\n",
            "Epoch 357/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1238 - accuracy: 0.9511 - val_loss: 1.1658 - val_accuracy: 0.7561\n",
            "Epoch 358/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1221 - accuracy: 0.9633 - val_loss: 1.4653 - val_accuracy: 0.7236\n",
            "Epoch 359/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1173 - accuracy: 0.9572 - val_loss: 1.2601 - val_accuracy: 0.7480\n",
            "Epoch 360/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1162 - accuracy: 0.9572 - val_loss: 1.2385 - val_accuracy: 0.7886\n",
            "Epoch 361/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2021 - accuracy: 0.9287 - val_loss: 1.3353 - val_accuracy: 0.7154\n",
            "Epoch 362/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1485 - accuracy: 0.9389 - val_loss: 1.4528 - val_accuracy: 0.7236\n",
            "Epoch 363/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1358 - accuracy: 0.9450 - val_loss: 1.1925 - val_accuracy: 0.7805\n",
            "Epoch 364/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1767 - accuracy: 0.9348 - val_loss: 1.2757 - val_accuracy: 0.7236\n",
            "Epoch 365/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2343 - accuracy: 0.9104 - val_loss: 1.2661 - val_accuracy: 0.7317\n",
            "Epoch 366/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1643 - accuracy: 0.9328 - val_loss: 1.2604 - val_accuracy: 0.7561\n",
            "Epoch 367/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1337 - accuracy: 0.9491 - val_loss: 1.2471 - val_accuracy: 0.7317\n",
            "Epoch 368/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1250 - accuracy: 0.9491 - val_loss: 1.3142 - val_accuracy: 0.7886\n",
            "Epoch 369/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1248 - accuracy: 0.9511 - val_loss: 1.3157 - val_accuracy: 0.7398\n",
            "Epoch 370/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1089 - accuracy: 0.9654 - val_loss: 1.2667 - val_accuracy: 0.7886\n",
            "Epoch 371/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1091 - accuracy: 0.9552 - val_loss: 1.2518 - val_accuracy: 0.7724\n",
            "Epoch 372/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1368 - accuracy: 0.9470 - val_loss: 1.3016 - val_accuracy: 0.7561\n",
            "Epoch 373/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1123 - accuracy: 0.9532 - val_loss: 1.3016 - val_accuracy: 0.7480\n",
            "Epoch 374/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1187 - accuracy: 0.9593 - val_loss: 1.1258 - val_accuracy: 0.7724\n",
            "Epoch 375/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1199 - accuracy: 0.9613 - val_loss: 1.2805 - val_accuracy: 0.7805\n",
            "Epoch 376/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1142 - accuracy: 0.9593 - val_loss: 1.4066 - val_accuracy: 0.7480\n",
            "Epoch 377/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1811 - accuracy: 0.9267 - val_loss: 1.2848 - val_accuracy: 0.7561\n",
            "Epoch 378/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1508 - accuracy: 0.9348 - val_loss: 1.1909 - val_accuracy: 0.7236\n",
            "Epoch 379/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1265 - accuracy: 0.9593 - val_loss: 1.4252 - val_accuracy: 0.7480\n",
            "Epoch 380/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1393 - accuracy: 0.9409 - val_loss: 1.2720 - val_accuracy: 0.7805\n",
            "Epoch 381/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1157 - accuracy: 0.9511 - val_loss: 1.2894 - val_accuracy: 0.7724\n",
            "Epoch 382/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1273 - accuracy: 0.9511 - val_loss: 1.4945 - val_accuracy: 0.7154\n",
            "Epoch 383/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2575 - accuracy: 0.9063 - val_loss: 1.2988 - val_accuracy: 0.7805\n",
            "Epoch 384/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1512 - accuracy: 0.9450 - val_loss: 1.2647 - val_accuracy: 0.7724\n",
            "Epoch 385/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1512 - accuracy: 0.9409 - val_loss: 1.1968 - val_accuracy: 0.7561\n",
            "Epoch 386/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1006 - accuracy: 0.9593 - val_loss: 1.3013 - val_accuracy: 0.7480\n",
            "Epoch 387/750\n",
            "123/123 [==============================] - 1s 7ms/step - loss: 0.1193 - accuracy: 0.9572 - val_loss: 1.2973 - val_accuracy: 0.7398\n",
            "Epoch 388/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1484 - accuracy: 0.9450 - val_loss: 1.2602 - val_accuracy: 0.7724\n",
            "Epoch 389/750\n",
            "123/123 [==============================] - 1s 7ms/step - loss: 0.1489 - accuracy: 0.9552 - val_loss: 1.2746 - val_accuracy: 0.7724\n",
            "Epoch 390/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1561 - accuracy: 0.9450 - val_loss: 1.2397 - val_accuracy: 0.7724\n",
            "Epoch 391/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.9145 - val_loss: 1.2820 - val_accuracy: 0.7154\n",
            "Epoch 392/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1134 - accuracy: 0.9552 - val_loss: 1.4826 - val_accuracy: 0.7398\n",
            "Epoch 393/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1331 - accuracy: 0.9450 - val_loss: 1.2921 - val_accuracy: 0.7561\n",
            "Epoch 394/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1311 - accuracy: 0.9389 - val_loss: 1.1545 - val_accuracy: 0.7236\n",
            "Epoch 395/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1127 - accuracy: 0.9470 - val_loss: 1.3107 - val_accuracy: 0.7642\n",
            "Epoch 396/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0930 - accuracy: 0.9674 - val_loss: 1.2728 - val_accuracy: 0.7724\n",
            "Epoch 397/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1155 - accuracy: 0.9552 - val_loss: 1.1344 - val_accuracy: 0.7642\n",
            "Epoch 398/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1140 - accuracy: 0.9572 - val_loss: 1.3252 - val_accuracy: 0.7480\n",
            "Epoch 399/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2176 - accuracy: 0.9389 - val_loss: 1.0852 - val_accuracy: 0.7724\n",
            "Epoch 400/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2548 - accuracy: 0.9145 - val_loss: 1.2387 - val_accuracy: 0.7317\n",
            "Epoch 401/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1688 - accuracy: 0.9267 - val_loss: 1.1763 - val_accuracy: 0.7236\n",
            "Epoch 402/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1479 - accuracy: 0.9328 - val_loss: 1.3417 - val_accuracy: 0.7317\n",
            "Epoch 403/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1185 - accuracy: 0.9511 - val_loss: 1.1505 - val_accuracy: 0.7561\n",
            "Epoch 404/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1302 - accuracy: 0.9389 - val_loss: 1.3003 - val_accuracy: 0.7642\n",
            "Epoch 405/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1164 - accuracy: 0.9572 - val_loss: 1.1376 - val_accuracy: 0.7480\n",
            "Epoch 406/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1158 - accuracy: 0.9593 - val_loss: 1.2745 - val_accuracy: 0.7317\n",
            "Epoch 407/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1056 - accuracy: 0.9613 - val_loss: 1.5084 - val_accuracy: 0.7317\n",
            "Epoch 408/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0956 - accuracy: 0.9613 - val_loss: 1.2863 - val_accuracy: 0.7480\n",
            "Epoch 409/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1173 - accuracy: 0.9593 - val_loss: 1.3532 - val_accuracy: 0.7642\n",
            "Epoch 410/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1234 - accuracy: 0.9511 - val_loss: 1.2026 - val_accuracy: 0.7073\n",
            "Epoch 411/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1165 - accuracy: 0.9552 - val_loss: 1.2801 - val_accuracy: 0.7561\n",
            "Epoch 412/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1250 - accuracy: 0.9552 - val_loss: 1.2545 - val_accuracy: 0.7480\n",
            "Epoch 413/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1384 - accuracy: 0.9511 - val_loss: 1.3116 - val_accuracy: 0.7561\n",
            "Epoch 414/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1135 - accuracy: 0.9654 - val_loss: 1.3222 - val_accuracy: 0.7642\n",
            "Epoch 415/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1051 - accuracy: 0.9552 - val_loss: 1.3360 - val_accuracy: 0.7561\n",
            "Epoch 416/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1472 - accuracy: 0.9409 - val_loss: 1.3238 - val_accuracy: 0.7642\n",
            "Epoch 417/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0961 - accuracy: 0.9695 - val_loss: 1.3352 - val_accuracy: 0.7886\n",
            "Epoch 418/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1114 - accuracy: 0.9511 - val_loss: 1.1875 - val_accuracy: 0.7805\n",
            "Epoch 419/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1225 - accuracy: 0.9532 - val_loss: 1.3174 - val_accuracy: 0.7561\n",
            "Epoch 420/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2380 - accuracy: 0.9022 - val_loss: 1.2518 - val_accuracy: 0.7561\n",
            "Epoch 421/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.9430 - val_loss: 1.3023 - val_accuracy: 0.7642\n",
            "Epoch 422/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1020 - accuracy: 0.9695 - val_loss: 1.2959 - val_accuracy: 0.7724\n",
            "Epoch 423/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1088 - accuracy: 0.9552 - val_loss: 1.3696 - val_accuracy: 0.7561\n",
            "Epoch 424/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0969 - accuracy: 0.9654 - val_loss: 1.3143 - val_accuracy: 0.7724\n",
            "Epoch 425/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0931 - accuracy: 0.9695 - val_loss: 1.2870 - val_accuracy: 0.7886\n",
            "Epoch 426/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1157 - accuracy: 0.9552 - val_loss: 1.2993 - val_accuracy: 0.7561\n",
            "Epoch 427/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1046 - accuracy: 0.9572 - val_loss: 1.3393 - val_accuracy: 0.7886\n",
            "Epoch 428/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0924 - accuracy: 0.9572 - val_loss: 1.3932 - val_accuracy: 0.7642\n",
            "Epoch 429/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1838 - accuracy: 0.9348 - val_loss: 1.2916 - val_accuracy: 0.7317\n",
            "Epoch 430/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2319 - accuracy: 0.9084 - val_loss: 1.3978 - val_accuracy: 0.7642\n",
            "Epoch 431/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2295 - accuracy: 0.9226 - val_loss: 1.2389 - val_accuracy: 0.7561\n",
            "Epoch 432/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1178 - accuracy: 0.9593 - val_loss: 1.3096 - val_accuracy: 0.7805\n",
            "Epoch 433/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0968 - accuracy: 0.9593 - val_loss: 1.2924 - val_accuracy: 0.7805\n",
            "Epoch 434/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1080 - accuracy: 0.9491 - val_loss: 1.3445 - val_accuracy: 0.7724\n",
            "Epoch 435/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1619 - accuracy: 0.9409 - val_loss: 1.2738 - val_accuracy: 0.7561\n",
            "Epoch 436/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0939 - accuracy: 0.9654 - val_loss: 1.2836 - val_accuracy: 0.7561\n",
            "Epoch 437/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0875 - accuracy: 0.9654 - val_loss: 1.2768 - val_accuracy: 0.7642\n",
            "Epoch 438/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0953 - accuracy: 0.9674 - val_loss: 1.2762 - val_accuracy: 0.7561\n",
            "Epoch 439/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1238 - accuracy: 0.9552 - val_loss: 1.2808 - val_accuracy: 0.7317\n",
            "Epoch 440/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1038 - accuracy: 0.9674 - val_loss: 1.5527 - val_accuracy: 0.6911\n",
            "Epoch 441/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2207 - accuracy: 0.9185 - val_loss: 1.2787 - val_accuracy: 0.7236\n",
            "Epoch 442/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1154 - accuracy: 0.9491 - val_loss: 1.3021 - val_accuracy: 0.7561\n",
            "Epoch 443/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1327 - accuracy: 0.9552 - val_loss: 1.2765 - val_accuracy: 0.7642\n",
            "Epoch 444/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1052 - accuracy: 0.9633 - val_loss: 1.2876 - val_accuracy: 0.7886\n",
            "Epoch 445/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1052 - accuracy: 0.9613 - val_loss: 1.3643 - val_accuracy: 0.7480\n",
            "Epoch 446/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1040 - accuracy: 0.9532 - val_loss: 1.3665 - val_accuracy: 0.7561\n",
            "Epoch 447/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0801 - accuracy: 0.9756 - val_loss: 1.3291 - val_accuracy: 0.7561\n",
            "Epoch 448/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0949 - accuracy: 0.9633 - val_loss: 1.2946 - val_accuracy: 0.7886\n",
            "Epoch 449/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1078 - accuracy: 0.9613 - val_loss: 1.3340 - val_accuracy: 0.7642\n",
            "Epoch 450/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0883 - accuracy: 0.9756 - val_loss: 1.4838 - val_accuracy: 0.7724\n",
            "Epoch 451/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1494 - accuracy: 0.9369 - val_loss: 1.4610 - val_accuracy: 0.7642\n",
            "Epoch 452/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0911 - accuracy: 0.9572 - val_loss: 1.4694 - val_accuracy: 0.7236\n",
            "Epoch 453/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1147 - accuracy: 0.9532 - val_loss: 1.3864 - val_accuracy: 0.7398\n",
            "Epoch 454/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0847 - accuracy: 0.9695 - val_loss: 1.4345 - val_accuracy: 0.7480\n",
            "Epoch 455/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1441 - accuracy: 0.9511 - val_loss: 1.4111 - val_accuracy: 0.7642\n",
            "Epoch 456/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0980 - accuracy: 0.9552 - val_loss: 1.5107 - val_accuracy: 0.7724\n",
            "Epoch 457/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1970 - accuracy: 0.9328 - val_loss: 1.3095 - val_accuracy: 0.7642\n",
            "Epoch 458/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1869 - accuracy: 0.9308 - val_loss: 1.3183 - val_accuracy: 0.7236\n",
            "Epoch 459/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1276 - accuracy: 0.9470 - val_loss: 1.3635 - val_accuracy: 0.7805\n",
            "Epoch 460/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1131 - accuracy: 0.9633 - val_loss: 1.4794 - val_accuracy: 0.7561\n",
            "Epoch 461/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0959 - accuracy: 0.9552 - val_loss: 1.3911 - val_accuracy: 0.7805\n",
            "Epoch 462/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1248 - accuracy: 0.9532 - val_loss: 1.3280 - val_accuracy: 0.7317\n",
            "Epoch 463/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1200 - accuracy: 0.9470 - val_loss: 1.4046 - val_accuracy: 0.7398\n",
            "Epoch 464/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0878 - accuracy: 0.9715 - val_loss: 1.5004 - val_accuracy: 0.7398\n",
            "Epoch 465/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0743 - accuracy: 0.9776 - val_loss: 1.4392 - val_accuracy: 0.7642\n",
            "Epoch 466/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0904 - accuracy: 0.9654 - val_loss: 1.4015 - val_accuracy: 0.7642\n",
            "Epoch 467/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1054 - accuracy: 0.9633 - val_loss: 1.4289 - val_accuracy: 0.7480\n",
            "Epoch 468/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0871 - accuracy: 0.9654 - val_loss: 1.4287 - val_accuracy: 0.7398\n",
            "Epoch 469/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0796 - accuracy: 0.9674 - val_loss: 1.3985 - val_accuracy: 0.7317\n",
            "Epoch 470/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1005 - accuracy: 0.9654 - val_loss: 1.4289 - val_accuracy: 0.7805\n",
            "Epoch 471/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0877 - accuracy: 0.9674 - val_loss: 1.4683 - val_accuracy: 0.7073\n",
            "Epoch 472/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0761 - accuracy: 0.9756 - val_loss: 1.4117 - val_accuracy: 0.7642\n",
            "Epoch 473/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0785 - accuracy: 0.9735 - val_loss: 1.4315 - val_accuracy: 0.7642\n",
            "Epoch 474/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0841 - accuracy: 0.9715 - val_loss: 1.4942 - val_accuracy: 0.7480\n",
            "Epoch 475/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0822 - accuracy: 0.9674 - val_loss: 1.4279 - val_accuracy: 0.7480\n",
            "Epoch 476/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1848 - accuracy: 0.9369 - val_loss: 1.3927 - val_accuracy: 0.7805\n",
            "Epoch 477/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1116 - accuracy: 0.9430 - val_loss: 1.4492 - val_accuracy: 0.7724\n",
            "Epoch 478/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0757 - accuracy: 0.9735 - val_loss: 1.4274 - val_accuracy: 0.7642\n",
            "Epoch 479/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1188 - accuracy: 0.9633 - val_loss: 1.4138 - val_accuracy: 0.7480\n",
            "Epoch 480/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0889 - accuracy: 0.9613 - val_loss: 1.4831 - val_accuracy: 0.7724\n",
            "Epoch 481/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0880 - accuracy: 0.9715 - val_loss: 1.4163 - val_accuracy: 0.7642\n",
            "Epoch 482/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0731 - accuracy: 0.9715 - val_loss: 1.5329 - val_accuracy: 0.7317\n",
            "Epoch 483/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0603 - accuracy: 0.9756 - val_loss: 1.4957 - val_accuracy: 0.7642\n",
            "Epoch 484/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0685 - accuracy: 0.9776 - val_loss: 1.5094 - val_accuracy: 0.7561\n",
            "Epoch 485/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0857 - accuracy: 0.9654 - val_loss: 1.4674 - val_accuracy: 0.7480\n",
            "Epoch 486/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1202 - accuracy: 0.9532 - val_loss: 1.6384 - val_accuracy: 0.6992\n",
            "Epoch 487/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1887 - accuracy: 0.9348 - val_loss: 1.4186 - val_accuracy: 0.7642\n",
            "Epoch 488/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1171 - accuracy: 0.9552 - val_loss: 1.5255 - val_accuracy: 0.7561\n",
            "Epoch 489/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1349 - accuracy: 0.9654 - val_loss: 1.3363 - val_accuracy: 0.7480\n",
            "Epoch 490/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1725 - accuracy: 0.9470 - val_loss: 1.2961 - val_accuracy: 0.7561\n",
            "Epoch 491/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1570 - accuracy: 0.9369 - val_loss: 1.2885 - val_accuracy: 0.7967\n",
            "Epoch 492/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1168 - accuracy: 0.9450 - val_loss: 1.3808 - val_accuracy: 0.7642\n",
            "Epoch 493/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0780 - accuracy: 0.9695 - val_loss: 1.2574 - val_accuracy: 0.7561\n",
            "Epoch 494/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0929 - accuracy: 0.9633 - val_loss: 1.4047 - val_accuracy: 0.7886\n",
            "Epoch 495/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0957 - accuracy: 0.9613 - val_loss: 1.3820 - val_accuracy: 0.7805\n",
            "Epoch 496/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0728 - accuracy: 0.9796 - val_loss: 1.3731 - val_accuracy: 0.7398\n",
            "Epoch 497/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0644 - accuracy: 0.9817 - val_loss: 1.4037 - val_accuracy: 0.7724\n",
            "Epoch 498/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0729 - accuracy: 0.9776 - val_loss: 1.3638 - val_accuracy: 0.7236\n",
            "Epoch 499/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1355 - accuracy: 0.9511 - val_loss: 1.3173 - val_accuracy: 0.7724\n",
            "Epoch 500/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0682 - accuracy: 0.9837 - val_loss: 1.4568 - val_accuracy: 0.7642\n",
            "Epoch 501/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0591 - accuracy: 0.9837 - val_loss: 1.4718 - val_accuracy: 0.7317\n",
            "Epoch 502/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0705 - accuracy: 0.9735 - val_loss: 1.3445 - val_accuracy: 0.7073\n",
            "Epoch 503/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1065 - accuracy: 0.9572 - val_loss: 1.5622 - val_accuracy: 0.7724\n",
            "Epoch 504/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0889 - accuracy: 0.9715 - val_loss: 1.5403 - val_accuracy: 0.7480\n",
            "Epoch 505/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0682 - accuracy: 0.9735 - val_loss: 1.4257 - val_accuracy: 0.7398\n",
            "Epoch 506/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0732 - accuracy: 0.9796 - val_loss: 1.4710 - val_accuracy: 0.7073\n",
            "Epoch 507/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0925 - accuracy: 0.9654 - val_loss: 1.4212 - val_accuracy: 0.7398\n",
            "Epoch 508/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0751 - accuracy: 0.9654 - val_loss: 1.4140 - val_accuracy: 0.7724\n",
            "Epoch 509/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0609 - accuracy: 0.9796 - val_loss: 1.5093 - val_accuracy: 0.7642\n",
            "Epoch 510/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0752 - accuracy: 0.9695 - val_loss: 1.4383 - val_accuracy: 0.7236\n",
            "Epoch 511/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1073 - accuracy: 0.9633 - val_loss: 1.5185 - val_accuracy: 0.7398\n",
            "Epoch 512/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1513 - accuracy: 0.9348 - val_loss: 1.4234 - val_accuracy: 0.7317\n",
            "Epoch 513/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0821 - accuracy: 0.9715 - val_loss: 1.8896 - val_accuracy: 0.7073\n",
            "Epoch 514/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1724 - accuracy: 0.9409 - val_loss: 1.5668 - val_accuracy: 0.7480\n",
            "Epoch 515/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0907 - accuracy: 0.9593 - val_loss: 1.5088 - val_accuracy: 0.7317\n",
            "Epoch 516/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1101 - accuracy: 0.9654 - val_loss: 1.3897 - val_accuracy: 0.7561\n",
            "Epoch 517/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0805 - accuracy: 0.9695 - val_loss: 1.5113 - val_accuracy: 0.7480\n",
            "Epoch 518/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0604 - accuracy: 0.9817 - val_loss: 1.4864 - val_accuracy: 0.7480\n",
            "Epoch 519/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0513 - accuracy: 0.9837 - val_loss: 1.4838 - val_accuracy: 0.7480\n",
            "Epoch 520/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0746 - accuracy: 0.9654 - val_loss: 1.5226 - val_accuracy: 0.7642\n",
            "Epoch 521/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0731 - accuracy: 0.9715 - val_loss: 1.5490 - val_accuracy: 0.7642\n",
            "Epoch 522/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0625 - accuracy: 0.9756 - val_loss: 1.5059 - val_accuracy: 0.7480\n",
            "Epoch 523/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1382 - accuracy: 0.9409 - val_loss: 1.5232 - val_accuracy: 0.7561\n",
            "Epoch 524/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1675 - accuracy: 0.9409 - val_loss: 1.5413 - val_accuracy: 0.7642\n",
            "Epoch 525/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1175 - accuracy: 0.9593 - val_loss: 1.4025 - val_accuracy: 0.7561\n",
            "Epoch 526/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1591 - accuracy: 0.9348 - val_loss: 1.4542 - val_accuracy: 0.7805\n",
            "Epoch 527/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1532 - accuracy: 0.9348 - val_loss: 1.4680 - val_accuracy: 0.7480\n",
            "Epoch 528/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0796 - accuracy: 0.9654 - val_loss: 1.4738 - val_accuracy: 0.7480\n",
            "Epoch 529/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0845 - accuracy: 0.9613 - val_loss: 1.4833 - val_accuracy: 0.7236\n",
            "Epoch 530/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0866 - accuracy: 0.9633 - val_loss: 1.5116 - val_accuracy: 0.7236\n",
            "Epoch 531/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1256 - accuracy: 0.9450 - val_loss: 1.3933 - val_accuracy: 0.7398\n",
            "Epoch 532/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0761 - accuracy: 0.9715 - val_loss: 1.4735 - val_accuracy: 0.7480\n",
            "Epoch 533/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0716 - accuracy: 0.9776 - val_loss: 1.3838 - val_accuracy: 0.7724\n",
            "Epoch 534/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0718 - accuracy: 0.9735 - val_loss: 1.4673 - val_accuracy: 0.7480\n",
            "Epoch 535/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0604 - accuracy: 0.9735 - val_loss: 1.4814 - val_accuracy: 0.7398\n",
            "Epoch 536/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0690 - accuracy: 0.9654 - val_loss: 1.4952 - val_accuracy: 0.7398\n",
            "Epoch 537/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0516 - accuracy: 0.9878 - val_loss: 1.5231 - val_accuracy: 0.7561\n",
            "Epoch 538/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0503 - accuracy: 0.9817 - val_loss: 1.5549 - val_accuracy: 0.7642\n",
            "Epoch 539/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0535 - accuracy: 0.9796 - val_loss: 1.5099 - val_accuracy: 0.7561\n",
            "Epoch 540/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0637 - accuracy: 0.9735 - val_loss: 1.5161 - val_accuracy: 0.7561\n",
            "Epoch 541/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1073 - accuracy: 0.9613 - val_loss: 1.5899 - val_accuracy: 0.7480\n",
            "Epoch 542/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1418 - accuracy: 0.9389 - val_loss: 1.5164 - val_accuracy: 0.7073\n",
            "Epoch 543/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 0.9735 - val_loss: 1.5446 - val_accuracy: 0.7480\n",
            "Epoch 544/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0795 - accuracy: 0.9776 - val_loss: 1.5818 - val_accuracy: 0.7073\n",
            "Epoch 545/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1362 - accuracy: 0.9409 - val_loss: 1.6201 - val_accuracy: 0.7480\n",
            "Epoch 546/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1076 - accuracy: 0.9572 - val_loss: 1.4484 - val_accuracy: 0.7642\n",
            "Epoch 547/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1556 - accuracy: 0.9409 - val_loss: 1.5513 - val_accuracy: 0.7724\n",
            "Epoch 548/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1567 - accuracy: 0.9389 - val_loss: 1.6223 - val_accuracy: 0.7236\n",
            "Epoch 549/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1528 - accuracy: 0.9470 - val_loss: 1.7601 - val_accuracy: 0.6992\n",
            "Epoch 550/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1206 - accuracy: 0.9552 - val_loss: 1.5638 - val_accuracy: 0.7805\n",
            "Epoch 551/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0846 - accuracy: 0.9613 - val_loss: 1.4632 - val_accuracy: 0.7724\n",
            "Epoch 552/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1155 - accuracy: 0.9613 - val_loss: 1.4626 - val_accuracy: 0.7154\n",
            "Epoch 553/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0680 - accuracy: 0.9695 - val_loss: 1.4468 - val_accuracy: 0.7561\n",
            "Epoch 554/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0659 - accuracy: 0.9776 - val_loss: 1.5115 - val_accuracy: 0.7724\n",
            "Epoch 555/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0690 - accuracy: 0.9654 - val_loss: 1.4769 - val_accuracy: 0.7561\n",
            "Epoch 556/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0470 - accuracy: 0.9857 - val_loss: 1.5441 - val_accuracy: 0.7642\n",
            "Epoch 557/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0533 - accuracy: 0.9776 - val_loss: 1.5933 - val_accuracy: 0.6992\n",
            "Epoch 558/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0590 - accuracy: 0.9776 - val_loss: 1.6784 - val_accuracy: 0.7480\n",
            "Epoch 559/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0927 - accuracy: 0.9532 - val_loss: 1.4846 - val_accuracy: 0.6992\n",
            "Epoch 560/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2633 - accuracy: 0.9104 - val_loss: 1.5208 - val_accuracy: 0.7236\n",
            "Epoch 561/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2232 - accuracy: 0.9124 - val_loss: 1.6051 - val_accuracy: 0.7154\n",
            "Epoch 562/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1141 - accuracy: 0.9532 - val_loss: 1.5320 - val_accuracy: 0.7480\n",
            "Epoch 563/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1324 - accuracy: 0.9593 - val_loss: 1.4759 - val_accuracy: 0.7805\n",
            "Epoch 564/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1462 - accuracy: 0.9491 - val_loss: 1.4985 - val_accuracy: 0.7642\n",
            "Epoch 565/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1174 - accuracy: 0.9470 - val_loss: 1.5088 - val_accuracy: 0.7317\n",
            "Epoch 566/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1196 - accuracy: 0.9633 - val_loss: 1.5626 - val_accuracy: 0.7561\n",
            "Epoch 567/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0744 - accuracy: 0.9695 - val_loss: 1.4442 - val_accuracy: 0.7724\n",
            "Epoch 568/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0709 - accuracy: 0.9715 - val_loss: 1.4907 - val_accuracy: 0.7642\n",
            "Epoch 569/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0944 - accuracy: 0.9674 - val_loss: 1.5779 - val_accuracy: 0.7317\n",
            "Epoch 570/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1235 - accuracy: 0.9572 - val_loss: 1.5632 - val_accuracy: 0.7480\n",
            "Epoch 571/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0973 - accuracy: 0.9674 - val_loss: 1.4284 - val_accuracy: 0.7480\n",
            "Epoch 572/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.9246 - val_loss: 1.3827 - val_accuracy: 0.7642\n",
            "Epoch 573/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0675 - accuracy: 0.9796 - val_loss: 1.4528 - val_accuracy: 0.7642\n",
            "Epoch 574/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0698 - accuracy: 0.9776 - val_loss: 1.4586 - val_accuracy: 0.7561\n",
            "Epoch 575/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0611 - accuracy: 0.9715 - val_loss: 1.6436 - val_accuracy: 0.7561\n",
            "Epoch 576/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0598 - accuracy: 0.9796 - val_loss: 1.4764 - val_accuracy: 0.7805\n",
            "Epoch 577/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0466 - accuracy: 0.9857 - val_loss: 1.5384 - val_accuracy: 0.7561\n",
            "Epoch 578/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0466 - accuracy: 0.9817 - val_loss: 1.5551 - val_accuracy: 0.7398\n",
            "Epoch 579/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0487 - accuracy: 0.9857 - val_loss: 1.5335 - val_accuracy: 0.7236\n",
            "Epoch 580/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0512 - accuracy: 0.9796 - val_loss: 1.5663 - val_accuracy: 0.7642\n",
            "Epoch 581/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0529 - accuracy: 0.9776 - val_loss: 1.7459 - val_accuracy: 0.7398\n",
            "Epoch 582/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0477 - accuracy: 0.9837 - val_loss: 1.5882 - val_accuracy: 0.7642\n",
            "Epoch 583/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0441 - accuracy: 0.9837 - val_loss: 1.5831 - val_accuracy: 0.7317\n",
            "Epoch 584/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0434 - accuracy: 0.9857 - val_loss: 1.5582 - val_accuracy: 0.7480\n",
            "Epoch 585/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0780 - accuracy: 0.9715 - val_loss: 1.5149 - val_accuracy: 0.7561\n",
            "Epoch 586/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0945 - accuracy: 0.9613 - val_loss: 1.5499 - val_accuracy: 0.7561\n",
            "Epoch 587/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0589 - accuracy: 0.9817 - val_loss: 1.5720 - val_accuracy: 0.7480\n",
            "Epoch 588/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0766 - accuracy: 0.9776 - val_loss: 1.5624 - val_accuracy: 0.7642\n",
            "Epoch 589/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0614 - accuracy: 0.9715 - val_loss: 1.5907 - val_accuracy: 0.7317\n",
            "Epoch 590/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.9715 - val_loss: 1.5479 - val_accuracy: 0.7642\n",
            "Epoch 591/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0871 - accuracy: 0.9674 - val_loss: 1.5100 - val_accuracy: 0.6992\n",
            "Epoch 592/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.9756 - val_loss: 1.6147 - val_accuracy: 0.7317\n",
            "Epoch 593/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0455 - accuracy: 0.9857 - val_loss: 1.5795 - val_accuracy: 0.7398\n",
            "Epoch 594/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0415 - accuracy: 0.9878 - val_loss: 1.5928 - val_accuracy: 0.7317\n",
            "Epoch 595/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0368 - accuracy: 0.9878 - val_loss: 1.5737 - val_accuracy: 0.7561\n",
            "Epoch 596/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0393 - accuracy: 0.9878 - val_loss: 1.6173 - val_accuracy: 0.7561\n",
            "Epoch 597/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0402 - accuracy: 0.9817 - val_loss: 1.6452 - val_accuracy: 0.7480\n",
            "Epoch 598/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1255 - accuracy: 0.9511 - val_loss: 1.5401 - val_accuracy: 0.7154\n",
            "Epoch 599/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1928 - accuracy: 0.9328 - val_loss: 1.5792 - val_accuracy: 0.7317\n",
            "Epoch 600/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1077 - accuracy: 0.9593 - val_loss: 1.5132 - val_accuracy: 0.7398\n",
            "Epoch 601/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1671 - accuracy: 0.9308 - val_loss: 1.6328 - val_accuracy: 0.7480\n",
            "Epoch 602/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1539 - accuracy: 0.9572 - val_loss: 1.4130 - val_accuracy: 0.7398\n",
            "Epoch 603/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.9817 - val_loss: 1.4603 - val_accuracy: 0.7480\n",
            "Epoch 604/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1375 - accuracy: 0.9491 - val_loss: 1.5273 - val_accuracy: 0.7398\n",
            "Epoch 605/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0576 - accuracy: 0.9776 - val_loss: 1.5686 - val_accuracy: 0.7480\n",
            "Epoch 606/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0600 - accuracy: 0.9715 - val_loss: 1.5381 - val_accuracy: 0.7236\n",
            "Epoch 607/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0426 - accuracy: 0.9857 - val_loss: 1.6620 - val_accuracy: 0.7642\n",
            "Epoch 608/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0482 - accuracy: 0.9837 - val_loss: 1.5469 - val_accuracy: 0.7317\n",
            "Epoch 609/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0508 - accuracy: 0.9878 - val_loss: 1.6130 - val_accuracy: 0.7805\n",
            "Epoch 610/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0379 - accuracy: 0.9837 - val_loss: 1.5982 - val_accuracy: 0.7317\n",
            "Epoch 611/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0575 - accuracy: 0.9796 - val_loss: 1.6855 - val_accuracy: 0.7724\n",
            "Epoch 612/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0528 - accuracy: 0.9756 - val_loss: 1.6935 - val_accuracy: 0.7480\n",
            "Epoch 613/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2625 - accuracy: 0.9063 - val_loss: 1.5830 - val_accuracy: 0.7154\n",
            "Epoch 614/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1250 - accuracy: 0.9613 - val_loss: 1.5554 - val_accuracy: 0.7480\n",
            "Epoch 615/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1334 - accuracy: 0.9552 - val_loss: 1.5425 - val_accuracy: 0.6829\n",
            "Epoch 616/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0505 - accuracy: 0.9796 - val_loss: 1.5142 - val_accuracy: 0.7724\n",
            "Epoch 617/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0477 - accuracy: 0.9857 - val_loss: 1.5870 - val_accuracy: 0.7398\n",
            "Epoch 618/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0405 - accuracy: 0.9898 - val_loss: 1.5928 - val_accuracy: 0.7561\n",
            "Epoch 619/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0785 - accuracy: 0.9654 - val_loss: 1.4967 - val_accuracy: 0.7236\n",
            "Epoch 620/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0468 - accuracy: 0.9796 - val_loss: 1.6288 - val_accuracy: 0.7480\n",
            "Epoch 621/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0386 - accuracy: 0.9878 - val_loss: 1.5664 - val_accuracy: 0.7642\n",
            "Epoch 622/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0877 - accuracy: 0.9633 - val_loss: 1.6435 - val_accuracy: 0.7398\n",
            "Epoch 623/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1084 - accuracy: 0.9613 - val_loss: 1.6129 - val_accuracy: 0.7236\n",
            "Epoch 624/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2109 - accuracy: 0.9226 - val_loss: 1.4547 - val_accuracy: 0.7154\n",
            "Epoch 625/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1389 - accuracy: 0.9470 - val_loss: 1.4655 - val_accuracy: 0.7642\n",
            "Epoch 626/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1008 - accuracy: 0.9613 - val_loss: 1.5038 - val_accuracy: 0.7317\n",
            "Epoch 627/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0808 - accuracy: 0.9654 - val_loss: 1.5132 - val_accuracy: 0.7236\n",
            "Epoch 628/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0659 - accuracy: 0.9776 - val_loss: 1.4727 - val_accuracy: 0.7561\n",
            "Epoch 629/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0797 - accuracy: 0.9756 - val_loss: 1.4947 - val_accuracy: 0.7642\n",
            "Epoch 630/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1416 - accuracy: 0.9491 - val_loss: 1.4396 - val_accuracy: 0.7154\n",
            "Epoch 631/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0905 - accuracy: 0.9674 - val_loss: 1.4881 - val_accuracy: 0.7317\n",
            "Epoch 632/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1061 - accuracy: 0.9552 - val_loss: 1.4832 - val_accuracy: 0.7561\n",
            "Epoch 633/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0605 - accuracy: 0.9817 - val_loss: 1.4704 - val_accuracy: 0.7480\n",
            "Epoch 634/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0377 - accuracy: 0.9878 - val_loss: 1.4825 - val_accuracy: 0.7398\n",
            "Epoch 635/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0458 - accuracy: 0.9837 - val_loss: 1.5063 - val_accuracy: 0.7398\n",
            "Epoch 636/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0462 - accuracy: 0.9857 - val_loss: 1.5236 - val_accuracy: 0.7398\n",
            "Epoch 637/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0376 - accuracy: 0.9857 - val_loss: 1.5279 - val_accuracy: 0.7561\n",
            "Epoch 638/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0326 - accuracy: 0.9919 - val_loss: 1.5361 - val_accuracy: 0.7398\n",
            "Epoch 639/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0332 - accuracy: 0.9878 - val_loss: 1.5442 - val_accuracy: 0.7398\n",
            "Epoch 640/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0331 - accuracy: 0.9898 - val_loss: 1.5870 - val_accuracy: 0.7480\n",
            "Epoch 641/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 0.9919 - val_loss: 1.5836 - val_accuracy: 0.7398\n",
            "Epoch 642/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0361 - accuracy: 0.9878 - val_loss: 1.6155 - val_accuracy: 0.7561\n",
            "Epoch 643/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0356 - accuracy: 0.9878 - val_loss: 1.6491 - val_accuracy: 0.7398\n",
            "Epoch 644/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0936 - accuracy: 0.9593 - val_loss: 1.7555 - val_accuracy: 0.7561\n",
            "Epoch 645/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2551 - accuracy: 0.9246 - val_loss: 1.5974 - val_accuracy: 0.7480\n",
            "Epoch 646/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0691 - accuracy: 0.9715 - val_loss: 1.5004 - val_accuracy: 0.7642\n",
            "Epoch 647/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 0.9878 - val_loss: 1.5232 - val_accuracy: 0.7398\n",
            "Epoch 648/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0415 - accuracy: 0.9878 - val_loss: 1.4804 - val_accuracy: 0.7642\n",
            "Epoch 649/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0297 - accuracy: 0.9898 - val_loss: 1.5894 - val_accuracy: 0.7642\n",
            "Epoch 650/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0372 - accuracy: 0.9898 - val_loss: 1.5445 - val_accuracy: 0.7561\n",
            "Epoch 651/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0300 - accuracy: 0.9898 - val_loss: 1.5497 - val_accuracy: 0.7480\n",
            "Epoch 652/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0257 - accuracy: 0.9959 - val_loss: 1.5353 - val_accuracy: 0.7398\n",
            "Epoch 653/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0329 - accuracy: 0.9939 - val_loss: 1.6531 - val_accuracy: 0.7480\n",
            "Epoch 654/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0313 - accuracy: 0.9878 - val_loss: 1.6265 - val_accuracy: 0.7480\n",
            "Epoch 655/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0298 - accuracy: 0.9919 - val_loss: 1.6102 - val_accuracy: 0.7642\n",
            "Epoch 656/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0320 - accuracy: 0.9878 - val_loss: 1.6052 - val_accuracy: 0.7561\n",
            "Epoch 657/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0298 - accuracy: 0.9898 - val_loss: 1.7199 - val_accuracy: 0.7642\n",
            "Epoch 658/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0295 - accuracy: 0.9939 - val_loss: 1.6717 - val_accuracy: 0.7398\n",
            "Epoch 659/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0565 - accuracy: 0.9715 - val_loss: 1.7128 - val_accuracy: 0.7724\n",
            "Epoch 660/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0295 - accuracy: 0.9959 - val_loss: 1.6893 - val_accuracy: 0.7317\n",
            "Epoch 661/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0224 - accuracy: 0.9939 - val_loss: 1.7285 - val_accuracy: 0.7480\n",
            "Epoch 662/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 1.7080 - val_accuracy: 0.7317\n",
            "Epoch 663/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0240 - accuracy: 0.9939 - val_loss: 1.7004 - val_accuracy: 0.7236\n",
            "Epoch 664/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0243 - accuracy: 0.9939 - val_loss: 1.6691 - val_accuracy: 0.7317\n",
            "Epoch 665/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0213 - accuracy: 0.9959 - val_loss: 1.6701 - val_accuracy: 0.7398\n",
            "Epoch 666/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0236 - accuracy: 0.9959 - val_loss: 1.7691 - val_accuracy: 0.7561\n",
            "Epoch 667/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1308 - accuracy: 0.9593 - val_loss: 1.6383 - val_accuracy: 0.7236\n",
            "Epoch 668/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2436 - accuracy: 0.9470 - val_loss: 1.5831 - val_accuracy: 0.7398\n",
            "Epoch 669/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0297 - accuracy: 0.9939 - val_loss: 1.6292 - val_accuracy: 0.7398\n",
            "Epoch 670/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0249 - accuracy: 0.9939 - val_loss: 1.6616 - val_accuracy: 0.7398\n",
            "Epoch 671/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0447 - accuracy: 0.9857 - val_loss: 1.6013 - val_accuracy: 0.7561\n",
            "Epoch 672/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0396 - accuracy: 0.9898 - val_loss: 1.6952 - val_accuracy: 0.7398\n",
            "Epoch 673/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0347 - accuracy: 0.9878 - val_loss: 1.6489 - val_accuracy: 0.7480\n",
            "Epoch 674/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0311 - accuracy: 0.9878 - val_loss: 1.7803 - val_accuracy: 0.7398\n",
            "Epoch 675/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0222 - accuracy: 0.9959 - val_loss: 1.7856 - val_accuracy: 0.7317\n",
            "Epoch 676/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1157 - accuracy: 0.9674 - val_loss: 1.8154 - val_accuracy: 0.7236\n",
            "Epoch 677/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2029 - accuracy: 0.9409 - val_loss: 1.6014 - val_accuracy: 0.7317\n",
            "Epoch 678/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1973 - accuracy: 0.9308 - val_loss: 1.9429 - val_accuracy: 0.6341\n",
            "Epoch 679/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1157 - accuracy: 0.9633 - val_loss: 1.5443 - val_accuracy: 0.7317\n",
            "Epoch 680/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0503 - accuracy: 0.9837 - val_loss: 1.6825 - val_accuracy: 0.7154\n",
            "Epoch 681/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1194 - accuracy: 0.9633 - val_loss: 1.4960 - val_accuracy: 0.7642\n",
            "Epoch 682/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0489 - accuracy: 0.9817 - val_loss: 1.6737 - val_accuracy: 0.7317\n",
            "Epoch 683/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0320 - accuracy: 0.9898 - val_loss: 1.8900 - val_accuracy: 0.7154\n",
            "Epoch 684/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1240 - accuracy: 0.9613 - val_loss: 1.5637 - val_accuracy: 0.7561\n",
            "Epoch 685/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0668 - accuracy: 0.9715 - val_loss: 1.6753 - val_accuracy: 0.7317\n",
            "Epoch 686/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0763 - accuracy: 0.9695 - val_loss: 1.7174 - val_accuracy: 0.7480\n",
            "Epoch 687/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0281 - accuracy: 0.9939 - val_loss: 1.7167 - val_accuracy: 0.7561\n",
            "Epoch 688/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0247 - accuracy: 0.9939 - val_loss: 1.7019 - val_accuracy: 0.7480\n",
            "Epoch 689/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 0.9817 - val_loss: 1.6415 - val_accuracy: 0.7480\n",
            "Epoch 690/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0301 - accuracy: 0.9878 - val_loss: 1.6967 - val_accuracy: 0.7398\n",
            "Epoch 691/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 0.9980 - val_loss: 1.7184 - val_accuracy: 0.7398\n",
            "Epoch 692/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0220 - accuracy: 0.9959 - val_loss: 1.7598 - val_accuracy: 0.7398\n",
            "Epoch 693/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0221 - accuracy: 0.9919 - val_loss: 1.7405 - val_accuracy: 0.7317\n",
            "Epoch 694/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0442 - accuracy: 0.9817 - val_loss: 1.7852 - val_accuracy: 0.7561\n",
            "Epoch 695/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2239 - accuracy: 0.9328 - val_loss: 1.5396 - val_accuracy: 0.7398\n",
            "Epoch 696/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1567 - accuracy: 0.9430 - val_loss: 1.6240 - val_accuracy: 0.7480\n",
            "Epoch 697/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0652 - accuracy: 0.9756 - val_loss: 1.5868 - val_accuracy: 0.7398\n",
            "Epoch 698/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0611 - accuracy: 0.9756 - val_loss: 1.6150 - val_accuracy: 0.7561\n",
            "Epoch 699/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0314 - accuracy: 0.9939 - val_loss: 1.7314 - val_accuracy: 0.7561\n",
            "Epoch 700/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3460 - accuracy: 0.8900 - val_loss: 1.7706 - val_accuracy: 0.7154\n",
            "Epoch 701/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2846 - accuracy: 0.9022 - val_loss: 1.4288 - val_accuracy: 0.6911\n",
            "Epoch 702/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0786 - accuracy: 0.9695 - val_loss: 1.3891 - val_accuracy: 0.7398\n",
            "Epoch 703/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1104 - accuracy: 0.9613 - val_loss: 1.3897 - val_accuracy: 0.7480\n",
            "Epoch 704/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0417 - accuracy: 0.9837 - val_loss: 1.4036 - val_accuracy: 0.7398\n",
            "Epoch 705/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0284 - accuracy: 0.9919 - val_loss: 1.4904 - val_accuracy: 0.7642\n",
            "Epoch 706/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0321 - accuracy: 0.9919 - val_loss: 1.4805 - val_accuracy: 0.7480\n",
            "Epoch 707/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0378 - accuracy: 0.9878 - val_loss: 1.5046 - val_accuracy: 0.7561\n",
            "Epoch 708/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0241 - accuracy: 0.9980 - val_loss: 1.5671 - val_accuracy: 0.7398\n",
            "Epoch 709/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0263 - accuracy: 0.9919 - val_loss: 1.5815 - val_accuracy: 0.7480\n",
            "Epoch 710/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 1.5719 - val_accuracy: 0.7480\n",
            "Epoch 711/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0225 - accuracy: 0.9919 - val_loss: 1.5769 - val_accuracy: 0.7236\n",
            "Epoch 712/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0223 - accuracy: 0.9959 - val_loss: 1.6535 - val_accuracy: 0.7317\n",
            "Epoch 713/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0265 - accuracy: 0.9919 - val_loss: 1.7250 - val_accuracy: 0.7236\n",
            "Epoch 714/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0213 - accuracy: 0.9980 - val_loss: 1.6887 - val_accuracy: 0.7561\n",
            "Epoch 715/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 1.6902 - val_accuracy: 0.7398\n",
            "Epoch 716/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 1.7299 - val_accuracy: 0.7398\n",
            "Epoch 717/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0416 - accuracy: 0.9878 - val_loss: 1.6472 - val_accuracy: 0.7398\n",
            "Epoch 718/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0182 - accuracy: 0.9980 - val_loss: 1.6732 - val_accuracy: 0.7561\n",
            "Epoch 719/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0187 - accuracy: 0.9959 - val_loss: 1.7521 - val_accuracy: 0.7317\n",
            "Epoch 720/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0251 - accuracy: 0.9898 - val_loss: 1.7246 - val_accuracy: 0.7480\n",
            "Epoch 721/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0190 - accuracy: 0.9959 - val_loss: 1.7751 - val_accuracy: 0.7236\n",
            "Epoch 722/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 1.7846 - val_accuracy: 0.7317\n",
            "Epoch 723/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 0.9959 - val_loss: 1.7991 - val_accuracy: 0.7480\n",
            "Epoch 724/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 1.7798 - val_accuracy: 0.7317\n",
            "Epoch 725/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9980 - val_loss: 1.7728 - val_accuracy: 0.7317\n",
            "Epoch 726/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 0.9980 - val_loss: 1.7454 - val_accuracy: 0.7480\n",
            "Epoch 727/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0178 - accuracy: 0.9980 - val_loss: 1.7850 - val_accuracy: 0.7317\n",
            "Epoch 728/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0132 - accuracy: 0.9980 - val_loss: 1.8381 - val_accuracy: 0.7317\n",
            "Epoch 729/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 1.8015 - val_accuracy: 0.7480\n",
            "Epoch 730/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9980 - val_loss: 1.8497 - val_accuracy: 0.7317\n",
            "Epoch 731/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 1.8625 - val_accuracy: 0.7398\n",
            "Epoch 732/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 0.9980 - val_loss: 1.7973 - val_accuracy: 0.7480\n",
            "Epoch 733/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0143 - accuracy: 0.9980 - val_loss: 1.8815 - val_accuracy: 0.7317\n",
            "Epoch 734/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.8590 - val_accuracy: 0.7398\n",
            "Epoch 735/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 0.9980 - val_loss: 1.8948 - val_accuracy: 0.7317\n",
            "Epoch 736/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0162 - accuracy: 0.9959 - val_loss: 1.9090 - val_accuracy: 0.7317\n",
            "Epoch 737/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0118 - accuracy: 0.9980 - val_loss: 1.8954 - val_accuracy: 0.7398\n",
            "Epoch 738/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0126 - accuracy: 0.9959 - val_loss: 1.8938 - val_accuracy: 0.7480\n",
            "Epoch 739/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 0.9980 - val_loss: 1.8948 - val_accuracy: 0.7398\n",
            "Epoch 740/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.8966 - val_accuracy: 0.7398\n",
            "Epoch 741/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.9425 - val_accuracy: 0.7317\n",
            "Epoch 742/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.9193 - val_accuracy: 0.7398\n",
            "Epoch 743/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9980 - val_loss: 1.9319 - val_accuracy: 0.7480\n",
            "Epoch 744/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.9415 - val_accuracy: 0.7480\n",
            "Epoch 745/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.9075 - val_accuracy: 0.7480\n",
            "Epoch 746/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.9891 - val_accuracy: 0.7317\n",
            "Epoch 747/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 2.0019 - val_accuracy: 0.7480\n",
            "Epoch 748/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 0.9959 - val_loss: 1.9872 - val_accuracy: 0.7398\n",
            "Epoch 749/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 0.9980 - val_loss: 1.9709 - val_accuracy: 0.7480\n",
            "Epoch 750/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 2.0100 - val_accuracy: 0.7317\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \n",
        "acc = hist.history['accuracy']\n",
        "val_acc = hist.history['val_accuracy']\n",
        "loss = hist.history['loss']\n",
        "val_loss = hist.history['val_loss']\n",
        " \n",
        "epochs = range(len(acc))\n",
        " \n",
        "plt.plot(epochs, acc, 'b', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.savefig('custom_trainvalacc.png')\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'b', label= 'Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label= 'validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.savefig('custom_trainvalloss.png')\n",
        "plt.figure()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "2foar6-xYI_U",
        "outputId": "41dc512a-9380-4c70-cc8f-371d1aaf7c1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd5gUVdbG3wMMIDmDBAkukpEwgIgSjGBGRVAUcVcxsGJG1E9FXde4yKIY0BVQQXRxURQRRUEwA4IERSXKgKQhMwwwcL4/Tl3qdnVVd/VMz0wznN/z9FPVt9Lt7pm3Tp177jnEzFAURVGKLsUKuwOKoihK/qJCryiKUsRRoVcURSniqNAriqIUcVToFUVRijgq9IqiKEUcFXolIYhoOhFdm+x9CxMiWkNEZ+XDeZmI/uKsv0xED4bZNxfX6U9En+a2nzHO252IMpJ9XqXgKVHYHVDyHyLaY70tA2A/gEPO+xuZeULYczFzr/zYt6jDzDcl4zxE1ADAagBpzJzjnHsCgNC/oXLsoUJ/DMDM5cw6Ea0BcD0zz/TuR0QljHgoilJ0UNfNMYx5NCeie4loI4CxRFSZiD4ioi1EtN1Zr2sdM5uIrnfWBxLRV0T0rLPvaiLqlct9GxLRHCLaTUQziWg0Eb0V0O8wfXyMiL52zvcpEVWztl9DRGuJKJOIHojx/XQioo1EVNxq601Ei531jkT0LRHtIKI/iegFIioZcK5xRPQP6/09zjEbiOivnn3PJ6KFRLSLiNYR0XBr8xxnuYOI9hBRZ/PdWsefSkTziGinszw17HcTCyJq5hy/g4iWEdFF1rbziOhn55zriehup72a8/vsIKJtRDSXiFR3Chj9wpVaAKoAqA9gEORvYqzz/gQA+wC8EOP4TgB+BVANwNMA/kNElIt9JwL4AUBVAMMBXBPjmmH6eBWA6wDUAFASgBGe5gBecs5f27leXfjAzN8D2AvgDM95JzrrhwDc4XyezgDOBHBLjH7D6UNPpz9nA2gMwDs+sBfAAACVAJwP4GYiusTZ1tVZVmLmcsz8refcVQBMAzDK+WwjAEwjoqqezxD13cTpcxqADwF86hx3K4AJRNTE2eU/EDdgeQAtAXzhtN8FIANAdQA1AdwPQPOuFDAq9MphAA8z835m3sfMmcz8HjNnMfNuAI8D6Bbj+LXM/CozHwIwHsDxkH/o0PsS0QkAOgB4iJkPMPNXAKYGXTBkH8cy82/MvA/AuwDaOO2XA/iImecw834ADzrfQRBvA7gSAIioPIDznDYw8wJm/o6Zc5h5DYBXfPrhxxVO/5Yy817Ijc3+fLOZeQkzH2bmxc71wpwXkBvD78z8ptOvtwEsB3ChtU/QdxOLUwCUA/Ck8xt9AeAjON8NgIMAmhNRBWbezsw/Wu3HA6jPzAeZeS5rgq0CR4Ve2cLM2eYNEZUholcc18YuiKugku2+8LDRrDBzlrNaLsF9awPYZrUBwLqgDofs40ZrPcvqU2373I7QZgZdC2K9X0pEpQBcCuBHZl7r9OMkxy2x0enHPyHWfTwi+gBgrefzdSKiWY5raieAm0Ke15x7radtLYA61vug7yZun5nZvina570MchNcS0RfElFnp/0ZACsAfEpEq4hoWLiPoSQTFXrFa13dBaAJgE7MXAGuqyDIHZMM/gRQhYjKWG31Yuyflz7+aZ/buWbVoJ2Z+WeIoPVCpNsGEBfQcgCNnX7cn5s+QNxPNhMhTzT1mLkigJet88azhjdAXFo2JwBYH6Jf8c5bz+NfP3JeZp7HzBdD3DrvQ54UwMy7mfkuZm4E4CIAdxLRmXnsi5IgKvSKl/IQn/cOx9/7cH5f0LGQ5wMYTkQlHWvwwhiH5KWPkwFcQESnOQOnjyL+/8FEALdBbij/9fRjF4A9RNQUwM0h+/AugIFE1Ny50Xj7Xx7yhJNNRB0hNxjDFoirqVHAuT8GcBIRXUVEJYioL4DmEDdLXvgeYv0PJaI0IuoO+Y0mOb9ZfyKqyMwHId/JYQAgoguI6C/OWMxOyLhGLFeZkg+o0CteRgI4DsBWAN8B+KSArtsfMqCZCeAfAN6BxPv7kes+MvMyAIMh4v0ngO2QwcJYGB/5F8y81Wq/GyLCuwG86vQ5TB+mO5/hC4hb4wvPLrcAeJSIdgN4CI517BybBRmT+NqJZDnFc+5MABdAnnoyAQwFcIGn3wnDzAcgwt4L8r2/CGAAMy93drkGwBrHhXUT5PcEZLB5JoA9AL4F8CIzz8pLX5TEIR0XUVIRInoHwHJmzvcnCkUp6qhFr6QERNSBiE4komJO+OHFEF+voih5RGfGKqlCLQD/gwyMZgC4mZkXFm6XFKVooK4bRVGUIo66bhRFUYo4Kem6qVatGjdo0KCwu6EoinLUsGDBgq3MXN1vW0oKfYMGDTB//vzC7oaiKMpRAxF5Z0QfQV03iqIoRRwVekVRlCKOCr2iKEoRJyV99H4cPHgQGRkZyM7Ojr+zUmiULl0adevWRVpaWmF3RVEUh6NG6DMyMlC+fHk0aNAAwXUtlMKEmZGZmYmMjAw0bNiwsLujKIrDUeO6yc7ORtWqVVXkUxgiQtWqVfWpS1FSjLhCT0T1nCIIPzt1Im/z2YeIaBQRrSCixUTUztp2LRH97ryuzUtnVeRTH/2NFCX1CGPR5wC4i5mbQ8qJDXbqbtr0gqQjbQypO/oScKR+5cOQWqEdATxMRJWT1HdFUZSiw9SpwDPP5Mup4wo9M/9p6j869Tl/QWRZMkAyDb7BwneQsm7HAzgXwGfMvI2ZtwP4DEDPpH6CAiAzMxNt2rRBmzZtUKtWLdSpU+fI+wMHDsQ8dv78+RgyZEjca5x66qlJ6evs2bNxwQUXJOVciqIUEC+9BFx1FfD88/ly+oQGY4moAYC2kGozNnUQWQMzw2kLavc79yDI0wBOOMFbWa1wqVq1KhYtWgQAGD58OMqVK4e77777yPacnByUKOH/VaanpyM9PT3uNb755pvkdFZRlKOLrCzglltkvVWrfLlE6MFYIioH4D0AtzPzrmR3hJnHMHM6M6dXr+6briGlGDhwIG666SZ06tQJQ4cOxQ8//IDOnTujbdu2OPXUU/Hrr78CiLSwhw8fjr/+9a/o3r07GjVqhFGjRh05X7ly5Y7s3717d1x++eVo2rQp+vfvD5Nh9OOPP0bTpk3Rvn17DBkyJK7lvm3bNlxyySVo3bo1TjnlFCxevBgA8OWXXx55Imnbti12796NP//8E127dkWbNm3QsmVLzJ07N+nfmaIoPjhGJAAgn8a4Qln0RJQGEfkJzPw/n13WI7LYcV2nbT2A7p722bnpqM3tt0d+N8mgTRtg5MjEjsnIyMA333yD4sWLY9euXZg7dy5KlCiBmTNn4v7778d7770Xdczy5csxa9Ys7N69G02aNMHNN98cFXO+cOFCLFu2DLVr10aXLl3w9ddfIz09HTfeeCPmzJmDhg0b4sorr4zbv4cffhht27bF+++/jy+++AIDBgzAokWL8Oyzz2L06NHo0qUL9uzZg9KlS2PMmDE499xz8cADD+DQoUPIyspK7MtQFCV37Nzprq9enS+XCBN1QwD+A+AXZh4RsNtUAAOc6JtTAOxk5j8BzABwDhFVdgZhz3HaigR9+vRB8eLFAQA7d+5Enz590LJlS9xxxx1YtmyZ7zHnn38+SpUqhWrVqqFGjRrYtGlT1D4dO3ZE3bp1UaxYMbRp0wZr1qzB8uXL0ahRoyPx6WGE/quvvsI111wDADjjjDOQmZmJXbt2oUuXLrjzzjsxatQo7NixAyVKlECHDh0wduxYDB8+HEuWLEH58uVz+7UoipIIu3fLskkTYPz4fLlEGIu+C6Tw7xIiMnb0/QBOAABmfhlSef48SKHjLADXOdu2EdFjAOY5xz3KzNvy2ulELe/8omzZskfWH3zwQfTo0QNTpkzBmjVr0L17d99jSpUqdWS9ePHiyMnJydU+eWHYsGE4//zz8fHHH6NLly6YMWMGunbtijlz5mDatGkYOHAg7rzzTgwYMCCp11UUxQcj9DNmAPXr58sl4go9M38FIKbjiMWJPDhg2+sAXs9V744idu7ciTp1ZJx53LhxST9/kyZNsGrVKqxZswYNGjTAO++8E/eY008/HRMmTMCDDz6I2bNno1q1aqhQoQJWrlyJVq1aoVWrVpg3bx6WL1+O4447DnXr1sUNN9yA/fv348cff1ShV45drr4aOPlk4J578u8amzbJdWbOlPfOOF1+cNTMjE11hg4divvuuw9t27ZNugUOAMcddxxefPFF9OzZE+3bt0f58uVRsWLFmMcMHz4cCxYsQOvWrTFs2DCMdx4LR44ciZYtW6J169ZIS0tDr169MHv2bJx88slo27Yt3nnnHdx2W9S8OEU5dpgwARg6NH+v8cYbrsgDQD66S1OyZmx6ejp7C4/88ssvaNasWSH1KDXYs2cPypUrB2bG4MGD0bhxY9xxxx2F3a0o9LdSjnpM9Et+6uOLLwKDLUdIHq9FRAuY2TeWWy36o4hXX30Vbdq0QYsWLbBz507ceOONhd0lRVESZd8+4IUXgI0bC+ySR032SgW44447UtKCVxQlAZ55Bnj4YVmvXBlo3z7ShZMPqEWvKIowcSLw44+F3YvU4t13gVmzkntOZ+IiAKBhQ+CTT4CDB5N7DQ9q0SuKIvTvL8sUHLcrNPr2lWWyvpMvvwTeew+oVw946CHgwgsBZy5OfqJCryiKUlBcfrksW7QArr++wC6rrhtFUZSC4Ntvga1bZX379gK9tAp9PmISlW3YsAGXmzu5h+7du8MbSupl5MiREblnzjvvPOzYsSPP/Rs+fDieffbZPJ9HUZQQDBzorv/rXwV6aRX6AqB27dqYPHlyro/3Cv3HH3+MSpUqJaNriqIUBGvWAL/95r7v0qVAL69CH5Jhw4Zh9OjRR94ba3jPnj0488wz0a5dO7Rq1QoffPBB1LFr1qxBy5YtAQD79u1Dv3790KxZM/Tu3Rv79u07st/NN9+M9PR0tGjRAg874VejRo3Chg0b0KNHD/To0QMA0KBBA2x1HgFHjBiBli1bomXLlhjpJAFas2YNmjVrhhtuuAEtWrTAOeecE3EdPxYtWoRTTjkFrVu3Ru/evbHdebQcNWoUmjdvjtatW6Nfv34A/NMcK4oSgwIWdi9H52BsIeQp7tu3L26//XYMdmayvfvuu5gxYwZKly6NKVOmoEKFCti6dStOOeUUXHTRRYG1U1966SWUKVMGv/zyCxYvXox27Y6U18Xjjz+OKlWq4NChQzjzzDOxePFiDBkyBCNGjMCsWbNQrVq1iHMtWLAAY8eOxffffw9mRqdOndCtWzdUrlwZv//+O95++228+uqruOKKK/Dee+/h6quvDvx8AwYMwPPPP49u3brhoYcewiOPPIKRI0fiySefxOrVq1GqVKkj7iK/NMeKUmTID//5hg3JP2cCqEUfkrZt22Lz5s3YsGEDfvrpJ1SuXBn16tUDM+P+++9H69atcdZZZ2H9+vW+qYcNc+bMOSK4rVu3RuvWrY9se/fdd9GuXTu0bdsWy5Ytw88//xyzT1999RV69+6NsmXLoly5crj00kuPFAxp2LAh2rRpAwBo37491qxZE3ienTt3YseOHejWrRsA4Nprr8WcOXOO9LF///546623jlTR8ktzrChFhpo1C7sHSefo/A8tpDzFffr0weTJk7Fx40b0deJrJ0yYgC1btmDBggVIS0tDgwYNkJ2dnfC5V69ejWeffRbz5s1D5cqVMXDgwFydx+BNdRzPdRPEtGnTMGfOHHz44Yd4/PHHsWTJEt80x02bNs11XxUlpUjm5KWvv5Zom0JGLfoE6Nu3LyZNmoTJkyejT58+AMQarlGjBtLS0jBr1iysXbs25jm6du2KiRMnAgCWLl16pLzfrl27ULZsWVSsWBGbNm3C9OnTjxxTvnx5Xz/46aefjvfffx9ZWVnYu3cvpkyZgtNPPz3hz1WxYkVUrlz5yNPAm2++iW7duuHw4cNYt24devTogaeeego7d+7Enj17jqQ5vvfee9GhQwcsX7484WsqSkoSb2LU4cNAQFEhX047TVIdV64s70uUAO66K/f9yyVHp0VfSLRo0QK7d+9GnTp1cPzxxwMA+vfvjwsvvBCtWrVCenp6XMv25ptvxnXXXYdmzZqhWbNmaN++PQAcSRHctGlT1KtXD12swZtBgwahZ8+eqF27NmZZ07HbtWuHgQMHomPHjgCA66+/Hm3bto3ppgli/PjxuOmmm5CVlYVGjRph7NixOHToEK6++mrs3LkTzIwhQ4agUqVKePDBBzFr1iwUK1YMLVq0QK9evRK+nqKkJB9/HHv7o48CjzwCLF0qk55iYWLmAfH733478Nxzee9jbmDmmC9I0ZDNAJYGbL8HwCLntRTAIQBVnG1rACxxts2Pdy3zat++PXv5+eefo9qU1ER/q6OQw4eZxZ4t7J4UPO++y/zmm7I+fLj7PdgvQ8eO8v7rr5mvuMI9zo9x4yLP8fTT+foxYmlsGNfNOAA9Y9wonmHmNszcBsB9AL7kyHKBPZztvnmSFUVJAQ4dyv2x69cDXbtGWrCpwvr1kfHrflxxBeDUVkascbG9e4EffpD1446ThGfmOD/+/FOWpjaDU4GuMIgr9Mw8B0DYOq9XAng7Tz1SFKXgOXw498eOGAHMnSsVkxK53kcf5X8Ctbp1peh2WGIJ/ddfu+tGxINYswa47z5Zr1FDllWqhO9HkknaYCwRlYFY/u9ZzQzgUyJaQESD4hw/iIjmE9H8LVu2+O7DmlUv5dHf6CglL0Jvji2WgJy89JJkbnQCE1KGWEJvB0SYoIugGep2umeTvCyRG06SSeZg7IUAvva4bU5j5vVEVAPAZ0S03HlCiIKZxwAYA0gpQe/20qVLIzMzE1WrVg2cjKQULsyMzMxMnUB1NFLQQm+EMiMj99fNKxMmuCUDDbGE3rbi//hDlt6Y+02bgBkzgGuvdduuvlqyVhbi/0Uyhb4fPG4bZl7vLDcT0RQAHQH4Cn086tati4yMDARZ+0pqULp0adStW7ewu6EkSl589ObYRPKqF6axtnCh1Gr1i28PEvr77ou06Lc59qyTuPAIzZu722wK2fhJitATUUUA3QBcbbWVBVCMmXc76+cAeDS310hLS0PDhg3z3FdFUXwoaIveUBiuvjvuCJ7EFCT0Tz4Z+X7XLlmWLBnZ7hX5eAPBBURcoSeitwF0B1CNiDIAPAwgDQCY+WVnt94APmXmvdahNQFMcdwsJQBMZOZPktd1RVGSRkELvbHoExH6XbtEiM3gZm4pX96//dAh4P33Yx9brx6wbp1r3XuF3kv16on3Lx+IK/TMfGWIfcZBwjDttlUATs5txxRFKUDyIvTGdZMboQ8LM1Cxooi0saYTPd5cM0jon38+/nlatowU+rS02PsHXauA0RQIiqLkzUdvbhJGSKdPB55+OvYxiVr0JkY/tymx7c9ni2+tWu76ypXxz1O7dmQ/vELvteALoB5sGFToFUVJjusmJ0eWb74ZP/FgIkKfkwNkZibeL/vc+/e768cdJ8vWrYFOnaL7FAsTZWOeKrzHMAPnnJN4X/MZzXWjKEpyXDcm6+OOHfEzQBqBDHPd5s2B339PvF92H/bvB8qWlbBIY41//jmwejUwbZrcTMK4bozQm3N4n4R27SrUGbBBqNAripIci/7AAVnGEvpNm1zLP4gFCyTL48nOEF+QyO/YIa8GDfy3W+U3ceCAiHL9+vL+hBOAatXk9dprkfVcY2HcPsait4V+/365jnHvpBDqulGUosywYcDbIbKSJMNHb8R9505X9L3UqiVpCWJZ9OnpUvFt7Vr/7eZG0bkzECvkeuNGd33/fsCuyVCmjLvujXE/5ZToc5l4eSdr7ZEwTPt727lTljVrAgMGyMSpFEEtekUpyjz1lCyvjBM8V9CuGyPWtu8ciPSrN2jgP6i7bx+wZAlg6iDs2RM9cQmQfDMGr9AbPz0AVKgQedxppwHffRfZNnq0PA2cdFJkuy30xsqvWBEYPz66P4WICr2iKLkX+nr13DQGtusmJycypNGL2de2/H/8MXrC0ZdfRh+blQXceKP7fvVqoFWr6P1Wr468ni309g2latXI4/zCRCtUALp1A7wz84OEPsVQ142iKLkT+sOHI3PVHDwoL+Mbf/314GONxW9b9O3bA2efHbmfXz3iffsiLXKTd8ZLLIt+0SJ33Sv0fjcnMzHK2x8/ofc+IaQAKvSKouTOR795c+T7gwddPzUgWRuXLPE/1ljyRuiDbjR+Qr93r+u2ASIF3CaW0A8b5q57hd7kj7cxQu+Nm1ehVxTlqCFRi/7xx92BScOBA+K2sQma4GSEfsMGuUEETSzym3l6992R5/Ub+M3MlMIghltvBdq2lfXp04EnnnC32a6WFStkINVLqVKyjGXRr1ghSxV6RVEKjESs9ESF/v/+L7rNa9EDIsJZWcAFF0idVbsdkBqt06cHX8cW1m7dZPmJJ2WWd0AXAD79VJamhrOdH952+wCuq+aCC4ATT5T3LVtG7uPnumnWzP2Ov/jCLfqtQq8oueD774PD9ZRg4kW+rF3r+tNtoc9tRkk/i37bNgnvnDZNhNTe11zr4ouDz2lb5c2b++/jJ/QmtPLVV6O3eYUeEHfQlCnue+93Zyx6+8mjaVNX6E0ytLJlUyaRmY0KvZLa/PqrxDXfeWdh96Tg2L5dPndeiXdzbNAAOOMMWbet/yCft2HuXP/2/fujhf7vf3crLJliIwDw3/9Gu34A4OGHgZtvdt/bn6FRI3+R9vucf/4p4nzCCdHb/M5Rpkykte4VejPRyh6oLVHCDRNdvVomSm3enLt0zflM6vVIUWxMMquFCwu3HwVJp06uyyEvhHkK+v57WdoW/bZtwG23ScFvv9qoXbv6n2vfvmjXTazaqt6YdEAs4u3b/fcvU8adLWsTZNHXqiXn8+In9F5soWcGKleO3qd4cfcGuX27lAq0J2KlECr0ipJq5Cavi5cdOyKLWXvx+uS9Qj9qlFjutWvLhKQw7N0bbdHHwh5QNbNRS5d2rWcvAwdGun8MXqHPzhafedOm/sIbptrTY4/F3l65crTQ+90MUoS4Qk9ErxPRZiJaGrC9OxHtJKJFzusha1tPIvqViFYQ0TC/4xVFyQf69AEuucR9b08eAqJdE7brxpsp0q+Enh9ZWYkJ/ZAh7rqZ8LRvH/DII9H7btokou03Mcr75PLMM8D69cA990SKeq1awJlnRtd59cOu+epl9mwJGy1KQg8pKNIzzj5zmbmN83oUAIioOIDRAHoBaA7gSiIKGE1RFCUUmZnhomnsCUEAcNFFke/txGKHDgHXXOO+9+Zoyc6WmPR9+4JzthOJRf/DD8F9sn3gt9wSKab16slyxw534NNwzz1uValGjSK3lSolfTLjBjk5Ejp5/vky/mD71Dt3BmbOjF8sJB7dukmGSlvod+wAKlXK23nzkbhCz8xzAMS4jQfSEcAKZl7FzAcATAIQY3hdUYog1avHz80elu3bJdvi/ffL+717g2ucVqsW+d47wGpb9Hfe6caAA25+HMPu3ZI8bODAYKGvXl3GUWIl8rIjVoxL5dlngauuktzwgCQ8A2QQ12DHuTduHDnBqVQpYOJEd9zg55/ls151VfQM19xUpoqFEXozGesot+jD0JmIfiKi6UTUwmmrA2CdtU+G06YoiVMYRaSDYAb+9a/YbgzD1q1SjDo3eP3oZibq//4ny3LlIgdt58xxLVuv6HitWFvoR42K3Y9ffpHll1+6N4T335f+GTdImJBC+/OYQdK77gImTJAQy1mzgJtukvbnn3dvDLalXKqUO0DvZcoUSXEMSDoFL96B4rxihH7ZMnnvF0WUIiRD6H8EUJ+ZTwbwPIA41XX9IaJBRDSfiOZv8SYOUpRUYu5cmZ1pRAkQkfLOAs1LRkjAda/88QfwzjuuOKeluee2Qxa7dRPL9sAB4NtvI8/lndEZL8YeAF5+WZZmolPdusA334hVffHFYjGbPnqfIPywr+kXDdO9e2RoonGL+LlExo2TiVO2lX7ppcBf/yo54xs3dtunTZNlIuMHADB1qvj7gzBCb24qLVoE71vI5FnomXkXM+9x1j8GkEZE1QCsB1DP2rWu0xZ0njHMnM7M6dVTcMKBohzBRHkYi37DBvEHewfw4hXYiIc5/rLLgH795DqAWNixapE+/nh0m9eijxfZU7u2m+v9gw9kuWCBzGI9/3x3PyPG3v/Zv/wl9vkTKZrtJ/TXXguce67//g0aRN4wTj1VlqedFv6aAHDhhXJDD8L20QPBE7pSgDwLPRHVIhJnGBF1dM6ZCWAegMZE1JCISgLoB2BqXq+nKPnKCy9IaF4i7N0ry8WLI9vDWM2x8OZsDxI2INJCtq18g/fG0L177GsvXOjmePcmJrOF3vTRFvqZM+VG8tln/kJZvHj4ik5A4ml/+/SJfF+pkiRBe+mlxM4TD1voL7kksZtXARMmvPJtAN8CaEJEGUT0NyK6iYjMc+vlAJYS0U8ARgHox0IOgL8DmAHgFwDvMvOy/PkYipIkbr1VQvAmTgx2vYQpIg0kz6KP5xLYtSuybJ7fdW3XzfrAB2uX0qWD481ty9XczDp0cNvOPFOWZ50F/POf0cePGRMult0QJprFzPAdPhx44IHo7U2aJHbNMBQv7g5yp6cn99xJJm7hEWaOWZqGmV8A8ELAto8BfJy7rilKIdK/v1jS110Xvc0MDMcbIM6rRW+sxXgWrdeCnzDBXa9fX7bbrhvjAorFccdFhzkabMu1eXOx/q++WvzjXvxCGf0mPcXChFb68dhj0k/zFNa+fcGlIChe3L2p+lW4SiG0wpSS2hRmtE2YqBog2HJPlkXvN8Xfxq8Kk8HcbGyLPt75ABHoIAvYdhPNmCEx+2lpEvXjdxM5/3y55syZ8j6WcPvhzRdvY7Jo7tkjg7MmPLMgsN1hKvSKkgfyUrQ6r5jUtDYZGcANN0S2GTH13pSS7aMP4tZbg7eZPthWblDsvZcgi94+V/XqblWo00/33/+jjyRqyAh9osQaeDY89JBMCmvTJtiCQLkAACAASURBVHfXyA3200qKC73mulFSm7yGKOYFP6G/+eZoV0mQoBeURR8LU2wjjEXvzQuTTJ92LKs8GRQv7h87n5/YA9Aq9IqSB8JY9BMnulEcX3zhFp0w/O9/safmDx7s74v3Cv3o0WKdegnKEllQFr0fJ5wAzJsn6YABEe0ZM2SC0kMPufvNnAlcfrnsZ6KHDMaiT4bPO0x+GS8DBsTOVV/Y1K7trqe40KvrRkltwlj0/fvLctw4N+LDdqNcdll0m82LL8py7NjIdu9Aoj0t3z5fkOsmjEW/fr34lcuXj56in6jQZ2W5Vrn91JGeLjejnj4pq0qXdm8GXsy5Ro2K/uyJkhuhHz8+b9fMb+pYE/398t6nECr0SmrwxhtAjx5ucitDYfro/QpT+xFkuYex6E1Mul9tVfPZY/nUlyyRG1JamkTKNG0aPYZQsmTw9H/vZyxXzk1LXLx45M0rL2Kf366bwqBBA1mWK+dOLktRVOiVgqdtW5lg8vDD8j47W2Y6NmwIrFoVua+x6Asi+iZWjvZY5Mai379fUu+uWRO8j23Rd+8O9OoloZP2xKwKFSKtSZOXxiYtLTgyxzsnYN06/xvU4MGSaye3hTWKF5eiIVdfnbvjU5GaNaVwi+3CSVHUR68UPIsWycQWgxHUdVYOvJNPlnqfiVj0djjk888n3i+vMMdzvRhhz42P/oYbJMY9VqKt2bOlAPW8eRJLP3RodHWkML5hv0Flg/f7rVQpOEHZI48A994b/3pBLFoUO6XA0UjHjgUb0plLVOiVwscIqhGdAwfEah00KLGom44d3XW7qIWhSZPYFnTfvv79ikeYqBtvebypIbKBjBkjU/cBd2DUO24QRujtY7zWZ2G6xpQCQ4VeKVj8rF/jnzYWsklDW6JEYkIUlCvd8NtvwCuvBG9/35N4NS9CP3Vq5BPK0KGR2/38/0OGRGadtK8fJPSxrPUw+6jQHxOo0CuxmTYNSGbaaG8IHxD96GvyrleqFG3Rf/21RNGEsfSZo4XsySeB994L19dEhd7cqHJyJCzwqqsi9xk6VHzikyb5i+/zz0cmG7OfAozQ+31/8bCvZX9vt96aeEZH5ahEB2OVYPbskbwk6eniJ07WOeNhbiyVKkULde/esj0zM36xi0OH/K3tyy8PN7gbVujtp5SRI8W37tcXk9v8yiujo4sMdsy6PeZgEnuFTctgY0e82J87XsERpcigFr0SjBHJeLnLEyFWXhaDEfqKFaMtd9tqBmJb5zk5eZu0lJMD3Hef+P79Qhy9cfRr10o1KZO/3cab+th269jYrhn7s5uYbVPh6b//BX79Nf5nACL98swpP7lHST5q0SvB5Ef6AbsIdRDG6i9VKtqiN+JqhPfyy4PPk5MTHBEThpwccfUAkdWkDKtXy6SeMNfYsEGSgcVzvQT506tUkeWll8pM30suCR/n7xX6338Pl8FSKTKoRa8EY6zmsPnXk4XJ8V2iRPDNJkxiroMHg0XYzAaNNRhpu278Zmn+8YekXpg0KX5fAHE1+aXttQlKN2BuAG+/LTNow4o8EDmD8/BhoFYtoF278McrRz1q0SvBFIbQb9oE3H67rHtLtQHRFn0sYln0V1whbpBYBZ3Dun0WLgy3X5Uq8Yt+eAe+BwyQPl56qbwvWTJcpI2NPeCaSkXWlQIjrtAT0esALgCwmZlb+mzvD+BeAARgN4CbmfknZ9sap+0QgBxmTu0yLEokRuiSKfQNGkgse1A62Vmz3PXixSMt+uxsV6iysuIXsDh4MDKBl5ennvIvUm2wJ3XFImza359+ivwuf/1Vnl5+/TU6ht9w4YWx3VNhKFtWbkZt2xZuNlCl0Ahj0Y+DVJB6I2D7agDdmHk7EfUCMAZAJ2t7D2bemqdeKoVDfgi9sdCDIlps10ZOjhtTn5kZOSt02zYJ/YzF8uXAm28Gb3/11fj9DaJbt3ADyzaHDkXmVj/pJFmamqw1a0q+n/PPBzp1ApYuFV98MjBpEtSiPyYJU0pwDhE1iLH9G+vtdwBSfz6wEo5EwgvHjgWuvz5+kQhT2zQoP4ztlpg92w1V9Eb+7NgRv18mk2V+cO+9iQt90JiDeSI47zzg9dfd9saNc98/Lya3fI8eyTunctSQ7MHYvwGYbr1nAJ8S0QIiGhTrQCIaRETziWj+lmRO0FFyj9eiz86WnOZe/vUviUp5I+ihz8IIvfGde/3gYaNkvCkF8kosN02vXtFtYQpWe/nxR/fGZvvNjdB789gkkzJlgGXLIuvJKscMSRN6IuoBEXo769FpzNwOQC8Ag4moa9DxzDyGmdOZOb16vIkwSsFgLHrjPrnnHslpvmBB5H6bNskyVoIuQKxZE1Fz8KCs//RT5D5h/dHJFPpPPxVffp8+0du++kpcROedF9luF+wOOzjaqpUr9K+95rZ36CBL7zWSTfPmuc8+qRzVJEXoiag1gNcAXMzMmaadmdc7y80ApgDo6H8GJSWxre1335VcMYAr7AYjXvEqEdmDlgcPyuSijrn8k8iL0I8f76ZIBmSAmMh1O9mZL7t0kW1eF5Mt9Pv3S+WmRLDL9HXqJPl+TG56RUkyeRZ6IjoBwP8AXMPMv1ntZYmovFkHcA6ApXm9nlKA2EL/zTeu5eqteGT8zn6DtkuWiK983z7XbQOIi8aOsEmUMD56QGLdf/jBnVEKSDHrE0903xsr19yo/NwyXt+6d59EB6y99Vh1tqqSj4QJr3wbQHcA1YgoA8DDANIAgJlfBvAQgKoAXiT5YzdhlDUBTHHaSgCYyMyf5MNnUPILezCWyBV6r4smlkV/yy3i/rALNFStKlE0ebHKveM4H30k/bjwwkgLvFw51zViqFw50oVhRNdY9H4Dpl6LPq8ukGQW3laUOISJurkyzvbrAVzv074KwMm575pS6NgWfbFirtC/9ZaEAppBSiOMJnSSWdL0VqokIg9IOoMff5T19HT/Qd1E8E488pbAMzcpvwHO0qUj4+eN6Jobld9sWa/4Gwu+efPIY/14443o7Sr0SgGiM2OVYLwWvbFqP/9cXua9WZqB1vfeix7YZJaB17Q0mbgTT+j79YudWsAM4taqJZWaOnSQMYDSpSX08ZFHZLtJ7wvIBCkzE9a2yM0+xqI/dAj497+BRo0i+w/ItXr3lvVVq9wcNLFcN3Z+nyuukPGORGe3KkoeUKFXgvFa9H4FrAH3hpCVJT55v+iVYcOAjRtFaGPNRjWEncE5cybQooWslykjN5u5c12htwXYLv5hC73JG2MLvbdClenPa68BZ50l67kpCP3mmzLYW9D5g5RjGk1qpgTjFfpdu/z3MxkZs7KkKIgfc+fKpKc//ggXL37FFa617MVu93OBxEscBvjfbIwbxi9XvLHogyaEhRXukiWBGjXC7asoSUKFvijQo0ewwCYCM/Dii+5Ap9d147XoDx+WfVavlvd2VE0swgxkXnZZdIy9wc6T4+cCCZPZ0Q6PNAwZIrNd/eLZjUUf5IuPlRxNUQoZFfqiwOzZkqM8LPv3A/ffHx31smoVMHiw5EXp0ycyZ7mfRb9rl7hDvvtO3u/dG05kw84AtUXcFMkGJO7dYFdPMuRW6IsVA7oGzOmLN1dg8GC3gpSipBgq9MciL78MPPGEDDjamLDJ7Gxg8mTgzjvdbRs2RIc0btsmYY328fFy3XzzTfjQRFvomzRx1ytUkOVTT/mfK4zrJtHwyFhzBQD53H/7m/v+xhvlphBUMlBRChAV+mMRkz+9Zk2Z7WpErH374GPGjYuu9zprVmSysR074gt9+/aRFn2XLu6gpsn/cvPNsvQK9k8/iWvF+LiDBmzDWPSJDoZ27izLmjWD96lc2Q05LV5cBoZXrkzsOoqSD2jUzbGIqVf6++8yoemZZ4C77078PKbMHiDjBGFmuqaludZ0w4bidjLW+pgxMmP2ZGf6hdf/3rq1LNu3l6eLwYP9r2GEPoxlH5Z//lPCJONllOzZE5g+PXLegaIUMir0RZnt2yVyxljAq1dLnhozyGr83t98k7s85XZagbAuCiLXoi9dWkTZWNclSgDNmrn7BlnmZcsCI0YEX8N8vlatwvUpDGlp7o0mFmayVby8P4pSgKjQF2WqVxfhMSJuJgB16SLL6U5G6WLF8lZEGxC3RVi8/vEgN0puY80bNwYeeMC/oLfN+ecnP5tjvOgcRSkE9K8x1fj8cxlsDIpZT4Sgwtdffx35vlgxNxY+P7jekyHDuFSMkL/8sljfpgpSXilWDPjHP4C6cWrgfPSRzFJNJn/5iyyT+TShKHlEhT7VeOghiVdfWoCJPhMR+qBar1dd5d9eunS00BuM0J95JrB4cWS6ApugkMdU5OKLJVvmddcVdk8U5Qgq9KlGYfh4ixVzJzvFskQffFCeOD78MHpbx44Ssmlz+eUSY++Nmzdx8GGKb2dmSmGQo4kOHTTFgZJSqI8+1TA+3nhhin7Yxae9+dr//DP4uGLF3GyQjz0WXJD60UdlGRSGaYc79uoF/Pe/su6Nvy9bNvzgb1AaBEVRQqMWfaoRbzBvyRIJSdyzJzqO3C4IcvXV7vrMmW4ueD+KFXMLaYdJOBY0s9X05/77gY8/dturV5eZtnfcEf/ciqIkHbXoU414WRu9IX4ZGe56drYbRWLXdf3ii9jnfPNNdz2MyyEol7oJjfRz/yR70FNRlNCEsuiJ6HUi2kxEviOEJIwiohVEtJiI2lnbriWi353XtcnqeJHF+OjthGKxsCNLbIveFtuw5wIkBHPqVGDRouB9ggZNL7tMbjB9+4a/nqIo+U5Yi34cgBcAvBGwvReAxs6rE4CXAHQioiqQ0oPpABjAAiKaysx5qCFXxDFCb6cIPnhQfO+JFN82NU1Lloy0+oPYuRMoX14sepOSYNIkcfl4o15iWf3t2gVvUxSlUAhl0TPzHADbYuxyMYA3WPgOQCUiOh7AuQA+Y+Ztjrh/BqBnXjt91HPokESu+A1IGteNbYWXLClWcjzL3BZ6k1I4J0dmw8ajQoVoAe/bFzj99PjHKoqS0iRrMLYOgHXW+wynLag9CiIaRETziWj+Fm+URlFh8WKgTh2ZtXnRRVJyz4vXon/sMVlOnhw7cgYAnn7aXTdCf/gwsHlz5H5BMe9BtGol/bXZtUti/hVFSXlSJuqGmccwczozp1evXr2wu5Ncpk+XWPBnn5V0vy+9JO1//OHuwywvr0Vvi2m8TIjjxkneGqLI2a/eG4Sdw71q1fiRNosXAx98ENlWvrxbrs9OIawoSsqRLKFfD8DOalXXaQtqP7Y47zzg3HPdbIYmvcFdd0nGRkDqiBYrJjneAX83TZiUtyaPjU1mZvD+69cDW7fGP28Q69YB8+bl/nhFUfKdZAn9VAADnOibUwDsZOY/AcwAcA4RVSaiygDOcdqOTfyiVcxs0pEjZWmE/qKLol0j65N0jySSm8+ll0qfgsIlw1C3rlj3iqKkLKGibojobQDdAVQjogxIJE0aADDzywA+BnAegBUAsgBc52zbRkSPATAm36PMHGtQt2jjl5/cWO5+9VaNf97w8MOJXa99+8h4eptp0xI7l6IoRy2hhJ6Zr4yznQH4VoFg5tcBvJ5414oIdgbJsWODt+/b5398uXLRlZ3CcvbZ/kKvmRUV5ZgiZQZjiyx28QxTk9UmntD7WfqGe+6Jbhs6VJbr1vmn6X3llcjapoqiFHlU6JNFTg4wfnykBR8vnQHgP0HKJtY5nn46OiXCU09J9E7dupFx9YbOnTWzoqIcY2ium2Tx4ovAbbdJ1sj16yV7Y5gomcxMt0ZqbnjySbHQ/WLs7ZQIppiJ1jFVlGMOtegT4dAhKaTtV/3JhCgOHy77nHEGcMMN4c67eHHu+9SrV2TtVhtj0d90k5vsTIVeUY45VOj9WLwYmDMnuv2DD8QH/uCD0duML96bBz4ZLFkC/PyzrPvluwlKMmYs+vr13eOCCm4rilJkObb+67dvB2bNkvjxWBhXijcXzcaNsjRRMF99JWkMTAx8IpQqFelaiUXLlrL84QegZk0RbhtTbKRp08j25s1l2bq1K/RhC34oilJkOLYs+quuklS6a9fm7niTBZJZfOunn547kQeAZcuAxx9P7JgOHdwC2l4r/ttvgblzI9sGDJCnk/POA664QtoqVMhdfxVFOWo5toT+999lGdaS9mKyQI4dC1Srlre+lCsHnHpq7o5dtUrCJ21OOSW6T0RuzPzTT0tyM5O+WFGUY4ZjS+iN28IbXrhvX+x4dYPfIGxuKV06svaqKZjtxU5AZmjYUMrzJULx4okfoyhKkeDYFHo71v3TTyUi5eKL4x/vN+EpDH41VkuVkhwxl14KjBgB/PKLm+AMACZMkBKAsSo9KYqihODYGow1k48OHHDbpk6V5cyZ8Y8Pa9E//7xY3RdcIO87dIiO4jFhjnZOejOoOmhQ4jnjFUVRAjg2hd720Rvx9kas+OEV+hNOiMwpDwDffQd06hTZ9tRTwOzZwH33idtozBj/MMl+/SSSx5vMTFEUJQ8UTdfNunWupW5jXDeLFkkUyoEDbiUmPx/9q68CF14o59u9W9wrNo0aRfrQq1ePFHkT4WIPvHbqBFx/vX+/y5QBXn8dqFEj/mdUFEUJSdG06M89V0R561aJRJk4EbjySteiHzRIlrffHlvozX7Z2UDHjtHbX3tNBlVN8jDvIG/NmvIUQASkpwOnnQaMGpX3z6coipIARdOiNxObvvlGlmYmqzdB2MGDsYXeMH++66Ixk5VGjABOPFFqwJpBVK9r5/bbZVm9uljrc+cCbdsm/nkURVHyQNEU+uOPl6UpaJ2dDaxe7d4ADPv2RQo9s9R39bJjB/DWW/KkcMYZ0launLu9Zk33Oja33CLuIXXFKIpSiIQSeiLqSUS/EtEKIhrms/05IlrkvH4joh3WtkPWNh/HeT7gFdb9+8Wf7uXOOyMnHmVnyyzSIC67zM0bb4dM1qolS79Zp2lp4fqsKIqST8T10RNRcQCjAZwNIAPAPCKaysw/m32Y+Q5r/1sB2P6JfczcJnldDoFtbQP+edmB6MFVO47dj+bN3RJ8ttCbAdk6dcL3UVEUpYAIY9F3BLCCmVcx8wEAkwDEml10JYC3k9G5hGEG3n5b8tDYBFVvMrRrJ0vjUw+ialUp3AEAjRu77Q0bAnfdBUyZklh/FUVRCoAwQl8HgJ1YJcNpi4KI6gNoCOALq7k0Ec0nou+I6JKgixDRIGe/+Vu2bAnRLR+WL5eJRt9+G9luz4T1w0xsike1alK+79dfIys7FSsGPPss0KRJYv1VFEUpAJI9GNsPwGRmtpW1PjOnA7gKwEgiOtHvQGYew8zpzJxePbc5WUx2yUT44Qfg2mvd95dcInVV/ahcWUT9pJNy1z9FUZRCIIzQrwdQz3pf12nzox88bhtmXu8sVwGYjUj/fXLZsMFdj1dJadgwYMECSU/QqJGEWm7dKikJTKhlly5SbMRgUhQoiqIcRYQR+nkAGhNRQyIqCRHzqOgZImoKoDKAb622ykRUylmvBqALgJ+9xyYNu26qyb9uc9tt7voTT7i+eUAqL1WtKhb73r3S1rWrhGjOng2MHp0vXVYURclv4kbdMHMOEf0dwAwAxQG8zszLiOhRAPOZ2Yh+PwCTmCNKGDUD8AoRHYbcVJ60o3WSjl2M29RIBYD335ekZSNGyAzXeNExJmqnnvMg062bvBRFUY5CiFOwtFx6ejrPnz8/8QObNZMBWUCiYP71L1nftCmxSUsHDwLjxwPXXafuGkVRjgqIaIEzHhpF0cl1s39/ZPy8XVc1qHh2EGlpwYnHFEVRjjKKTgqEUqWAefOkFmuLFkDfvu620qULr1+KoiiFTNGx6A3NmwNLl8r6998DkybFj8BRFEUpwhQ9obfp2NE/vbCiKMoxRNFx3SiKoii+qNAriqIUcVToFUVRijgq9IqiKEUcFXpFUZQijgq9oihKEUeFXlEUpYijQq8oilLEUaFXFEUp4qjQK4qiFHFU6BVFUYo4oYSeiHoS0a9EtIKIhvlsH0hEW4hokfO63tp2LRH97ryu9R6rKIqi5C9xk5oRUXEAowGcDSADwDwimupTKeodZv6759gqAB4GkA6AASxwjt2elN4riqIocQlj0XcEsIKZVzHzAQCTAFwc8vznAviMmbc54v4ZgJ6566qiKIqSG8IIfR0A66z3GU6bl8uIaDERTSaiegkeCyIaRETziWj+li1bQnRLURRFCUOyBmM/BNCAmVtDrPbxiZ6Amccwczozp1evXj1J3VIURVHCCP16APWs93WdtiMwcyYz73fevgagfdhjFUVRlPwljNDPA9CYiBoSUUkA/QBMtXcgouOttxcB+MVZnwHgHCKqTESVAZzjtCmKoigFRNyoG2bOIaK/QwS6OIDXmXkZET0KYD4zTwUwhIguApADYBuAgc6x24joMcjNAgAeZeZt+fA5FEVRlACImQu7D1Gkp6fz/PnzC7sbiqIoRw1EtICZ0/226cxYRVGUIo4KvaIoShFHhV5RFKWIo0KvKIpSxFGhVxRFKeKo0CuKohRxVOgVRVGKOCr0iqIoRRwVekVRlFywdy9w8GBh9yIcKvSKoii5oFw5oOdRUl1DhV5RFCWXfPFFYfcgHCr0Ssozezbw0UeF3QtFOXqJm71SUQqbHj1kmYL59xTlqEAteiXfmTQJuPzywu6Fohy7FEmhX7YMeOkl/23ffAPs3BnZtny5HJMbmIHffsvdsccKV14JvPdeYfdCUY5dipTrZtYsYMIE4D//kfebNgF9+gCHDwOrVgFLlgAPPgiceSYwc6Z7XLNmsjx8GCBK7JpvvAEMHCjX7t49GZ+i6MKc+PerKEreCWXRE1FPIvqViFYQ0TCf7XcS0c9EtJiIPiei+ta2Q0S0yHlN9R6bLDIzJdTJiDwAPPII0LIlkJ4OXHKJiDwgI+WLFwNXXQXUr+/u/9tvwM8/y/rzzwMvvgjMm4cI1q+P9BV/+60sc/tE4EefPsAHHyTvfAXFggUi5N9/7789O7tg+6Mo+YWtAYcOFV4/QsPMMV+Q8oErATQCUBLATwCae/bpAaCMs34zgHesbXviXcP7at++PeeG995j/ve/mR95hFl+CuYOHdz1eK+zzpLl0KGR7bNnM2/bxjx/vrwfN06u99xzzM2bS1t6OvPq1cyHD8uLmTk7m3n/fv++HjrE/MwzzGvXRrbv3+9e18umTcxTpuTqqykQhg+Xfv/f/0W2m8+TmZm783q/j19/le+2MFm+nHnpUv9tWVnBv/uxQteuzJddltxzLl/OXKYM88qViR2X27+7WBw86P5dZmUl//y5AVLa1V/HgzYc2QHoDGCG9f4+APfF2L8tgK+t9wUm9DZ//CFiyszcooV80hIlwou+93XeecxPPeW+b9DAf7+OHZnbtZPr1qrFfOKJzIMHM69YEdm/Dz+U/QcOZN6yhTknR9o3bgwW+rZtpX33buYRI5ivuy7+9zBypBxTEMLz8MNyrYceimw3nycjI3fntb+PXbtk/eqr4x+3f7/7vSYbu08LF4pxYG7wAHPr1vlz3aOFoL/hvDBsmJzz8cfDHzNtmhzzxRfJ7cu+fe5n3LkzuefOLbGEPozrpg6Addb7DKctiL8BmG69L01E84noOyK6JOggIhrk7Dd/y5YtIboVm3r1gGLOp/vgA+Cpp8R18NtvwF//CtSuDdx7r2y//XagUSNZb9DA/3wff+zuDwBr1vjv98MPwI8/yvk2bgRWrgRGjwZat5aB4KuuAs46C/jyS9l/3DigenWgTBlg3z5gm1U6/ccfI8+9cKEsJ04E7rwTGDs29ndw+LB8NgDYsQN4/XVg3brYx+SFw4dlGeSH37cvb+dnBrKyZH3KlPj7lyoF9OoVf78dO8TN530E378/XEjn6acDTz8tU+INixcH779kievyU8Jj/p/N31kY5syR5Xffxd6PCLj++vDntf9Wjoo0CEF3APMCcDmA16z31wB4IWDfqwF8B6CU1VbHWTYCsAbAifGumQyLPizG1bJlC/PcudL23/+KC2jdOuY2bZjPPtu9e5cvH23FFy/OfO65iT0hnHaaf/s//xn5fu9et69++xsrkllcSwsWuO9Hj3b3mzRJlq1aicvpnHPifzd79iT2XT7wgFxj+HB5v2ULc8OGbh8WL07sfAZzfHa2uMf8rMXff49+pA9rVd5wg+w3ebLblpXl/3Tid27zpLhtm/xe8a7r3f7qq/I3tnt3/L4eLZjPaJ6qk8GDD0b+fYXBuGGfeCL2fok8geTkMO/Y4R7z55/h+5OfII8W/XoA9az3dZ22CIjoLAAPALiImfdbN5L1znIVgNkQ107KQCSvatWA006TtssvB4YMAerWFSt6xgy5a+/bJ4O+48eLpZ6VBWzeLNs++QT4809gxQo5xwknyFOFoVQpWd5wgyy/+sq/P/ffH/m+bFng2WclmsiP3bulf+3by6Bz+/bSzzFj3IFlAOjXT5arVgF33AF8+mm0tbpmjRt6Om+e5PL45BMgJwf4/ffIffftA/r2BX75Rd4fPgw8/rj7nQISibR6deQxsdiyBXjhhWArev/+4HM0bgyceGLs8wexe7cs7cHirVtl+cor8Y831l12NpCRkfj1//lP4LPP3Ke8ffvkbzDoqfFoIjMzeecyFn0ig5/mbylWtFeYpzabEiWA/v3d90eDRR8mvHIegMZE1BAi8P0AXGXvQERtAbwCoCczb7baKwPIYub9RFQNQBcATyer8wUFkfy4JZxva8AAd9txx7nrtWrJ0oRpMgOXXQZcfTXQpIk8rjdpArz6amLXv+ee4G2LFkUnVipTRpbVq0fvbz/2ZmbKDQ4ANmwAGjYUF9NPP4l7AQCefNJ1f/zxh3vzmjIFePdd+ed7++1Il5D5pypbNvLa8aJubroJ+N//gFtv9f/ny84O7/7JyYm9fe9eFkwK9gAAFWFJREFUcaONGOH2177m9u2yLF48/rXMcdnZEtKbKMZTaT7bJ5/IvIPDh+X7OJrZvdv/7zA3+Llu/vEPoFIl4O9/9z8mjND7CTVz7GOmTYt9fKoR16Jn5hwAfwcwA8AvAN5l5mVE9CgRXeTs9gyAcgD+6wmjbAZgPhH9BGAWgCeZ+WcUccwfCJH8o156KdCihfgATzhBtqWlASNHAoMGyR/ViBHS/vXXMqZw+LBY5/Ho1i14m99Qhy2Uq1a563WcUZfFi+VJZf58eW+sTEBuDFu3ylPO0qXSVreuLC+7zN1vv/M8t2dP8LX9sPc3/8y29eZn0S9cGH1TsMcmgvj8c2DqVOC229w2c5477wTatZP1MEJv98+MISSC+dzmWL8bj+H33+P7m1OJ3HwfQZjfwv6bePBBMQyCCCP03r+pX38FSpYE3n8/XL+KhNADADN/zMwnMfOJzPy40/YQM0911s9i5prM3MZ5XeS0f8PMrZj5ZGf5n1jXORaoX18s4IwMERnjGrj9dvmnOPVU4KKL5A9z/nyxtF97DejcWawXAGjTBhg+3D3n2WeHu3aLFpHvO3US4ejcObL9mmv8Zxbv3y8Dj+3ayQ0JkD/ynTslht5g/rl37Yo83v6H+t//5BpZWfLP+Msv4k4ymEHp/fvdNq/QT5okfXn55cjrLFwoA+Be1qwRF9jTTwMVKkhbZma0CDz3nCsmJeI889pPDtnZiQmb1wVhPlssoe/WTX4v703UsHFj5He0cqV8nsIitwPwRMAwz4wdP6GPRxih9/5my5fL73rXXdH7+l37aBD6IjUz9mjB+MttiCLdQIbjjwf+9jd5AUCNGsCFFwJVqoiff906Ec09e4ChQ+UGMmuW/3WXLJHzbdok59m8GTjppOj9gtwFu3bJPwHgRjP8+98SaWRj/nG8qSa+/lomrgHuE8Att4hVZtxehk2bxK3kFXr7n9I8Pn/zTeSx3qiMgwflCaphQ7fNWGvffedayH7/sLZFv3OnCO24cW6bLWReoT90KPYTQVaW9Mt+D8QW+s2OY/T772WGt5fjj5ebsfl9zjlHntyuu05cHAWB3W/7+xg9WsaROnWKfbz5/Z56SlyHhtxE3YTxv3uF3vymfu4/v7+Ro0Hoi2Sum6LMDTeIKJYsKQN4y5fLoGmtWpKOwcz6XbAAePNNGTT69FMRYyIR23vuiRxcHTBAbiS//SazgYO46ir/dm+o4CuvAO+8A9x9d2S7EWbj9jE89li05fzYY0Dv3sCBA25bVlaksH7yiSztkFQg+knC+NttzKC4jZ/1affr669l/ML+XLZI7N8fGWIZZHUb9u51B4Lt6xuB8RMpI9bez2wzd667bgaVK1cOnrFsePZZd2wJENff+PGxj/HDtnrt7+fvfwdOOSX+8fb3Zq/nl0Xv/d3NNf2uY/89xmpLNdSiL4K0aiXLdu1kINjmxBPFdQFInve0NPnnM9ZS48YyNpCRIZZXlSru4K4RDUOtWuIqAORGceWVYqH/9lv0U0v9+uKe6dtXBnG92FZamTJyowAiRTsjI/Kf0vTHHgDNzo5+kpg1S1xiNn7jF35uF7vNiL4dWWNv91r0a9fK4HYQe/ZE3kgeeEDmOjzyiLz3E3oTveUn9EGDiobnnhN3VxBDh8oyK0sG0i+9VJ4av/1W3GxBYjltGlCxohu1Zguf+b0SscLt37x/fzcdiBHeRM5lSMR1Y27WYYVeLXolpenWTQSwmOevoGNH+SevUyfanfTDDyLmt98uTw+9e0v7HXeIK+GHHyKPueUWcSMY8fITeQC4+WZ33b5J2BV8Lr1UXBBe7PGBcuUiXSvmfGYQPBZ+Qr9+vfuPbG4ga9e62y+4wF33Cr3dL0BEzx5P2LMn2upfudIVRyPSOTnAjTdKPqUdO6TN7ynFr/+20Jubsh8//ujua54yzAS9V16Jdo8ZNm+W7+D00123ni2GEyfK+3hPNzb2U85UKzuW+R2M0NvXsV18NuYzxXoKCLLo/W4oKvRKkcX8ITdtCnToIL7W556TrJ/vvCMDxmagt2JFEcTly0UQR48WEbj0UuD884GTT45/Pe/gcCIcOgR8+GHujn3ttWgr+tAh+Ryvv+4+OdhhovZchR07RGyJgNKlI11U8+fLk4p9Q9u+PdLVYzBCY773JUtkXkTLlq6Y+1n08QaCzbW2bHHDZw3/+pe7boTW7pt3foAZxDZjR6afQKQYvvee/K3Y4h0Pr+vNfMfm+zBPY/bnnTJF+rN5c+Sx5veM5V7xjo2Yz+0XDqxCrxRZSpQQy9r2/RrS0mQA0NvWpEmkFV2+vJQDXLRI/vnWr5e0zt4QthdeAK69VsIfbWwrvWZN+WesX18GG4MYOTL+Z7NvPBkZMnnJYNJi9O4tgmZcG15MeuqBA8XqLldOXiNGyFhIdrbcIL1s2uRv6Zr0CZ9+KjcZv0HB336TMECbeBb9emeaY6tW0S4l26r1E+Xff3ctfMDN6mqXeDRPOl7reuPGxOYXeIXeGBFGUN95J/rpyUToeAMDjFUeS4zNZzcD4+Y32b1bjrNvcir0SpGmRw93clUyqF1bfOcXXyyDyMZ9NHiw/MOdcYaIS8+eYilfe62b3+bNN8U6Xr3aLWhy8smRE9H69RPhBeQm451UZvDmE/q//5Pl44+LmNat61rmQaGCLVu66++/LyJkxg/69nXnKHj580//Gc92DqOffnLdNTYffCBPWCtXum228L32mixt98OmTXLTMKJr3wTiCf2DD7pzC4L2efNNafeK4ciR4eaEGLxCb7AFdceOyCcO45by3hTNMWEsejNeYoSeWYIe6tWT3yroPCr0ihKCa66RfyDvP9Ff/gJMny7uIEBCM9eudecNELlpGqZPl8gSw8SJctzu3eJKmjzZHZA97zxZ1qolN5h16yLTDRQrJhZv8eL+ydMefVSW5onFGy5YooR7A1q4MDhCxk5MV6OG/z6jR0sEUhCTJ7vWtS18N9wgQmWE78wzRfRty/rtt93PbbspBg+WpV9oqNd9YihZUp5Errsu71EoYYR+9+7oiCcgupKZaQ8j9Mai93OnbdgQfJ4bbww+d6qgQq+kBMWLR8aUB+E3qHruueI+OvdcuQn8/LPrby1XTtbLlpXwyJ07xd0wZ44bP1+3rriBFiyQSKScHHeQtX17cdtccom4ndavF+v20CH3BnTuuWL1G4vwtddkTMIWog0bgi17QJ46vNSoIe4bP5eZYdgwGTxv1y7aj27yMD33nDsD+N//drf37y+T7/bujXQhLVsmAnnokDzZ2H0zuWuMG8hgvovFi10xfOGF4DkdBmYJ+7SfLoL8+bbQ79njnwvorbciz2X6khvXjY35Lf3O4x0XSEVU6JUiQ7lyIoymNKQfFSqI8J9+emR1MUDEslu3yFA8IhHuKVPEPVS7trQXKyZtY8dKLpcWLSS8FHCfOI47TmLH69aVp4dVq8TdcuutkbOAARkMtS3ohQvdBHle7LQU9v4msslgRP2EE9ybzDPPRO6zc6d8byblhcFYsBUqRN6AjSVvC/3UqW5US7lyrnA2bBiZ2A+IvqG99ZaE906aJDeV3btdi/6KKyL39Vr0CxbI7+C9+dsRSeZJJTeuG79zHg0x835oHL2i5JITT4zMmDlmjEymspN4jRolLyJxb5hsn4D48bduFXdK164iZPfcI3MX2rSJvFbnzhLPft55si+z3DxsV4x3ItoTT8jyL38Jdg0F8cILsqxQIdL1tHKlDObaQl+lioTR/uMfMnZinizq1JGBc8OZZ8pTkc10p3KFmYy3e7e4mEqXjp5EZwv9P/8pTwsNGsh57fGZTZukT0A4gTY3JnOj3btXJqbZYyPjx0tqkqNV6NWiV5QkUbp0dDSLSYPtR9WqEp3Utau777PPRqaq/vxzCRf95huxTu24cpPV9JlnpJhN3brAffdJm5k0B8jTRo0akVlX/Rg2TFxXgJtkr2xZGWR9/nm5UfXuLa4qW+ibN5eniR49xD1mcjLVry8WvqFZM3H9mPQMQPT4xfr1YtGXL++fysIwY4aIbo0aklbBxr75mfOHsejN+ffscZ/cDCYtSNB5guL4U4agRPWF+SrIwiOKcrRy+HBwPdTvvpOiGKaspeG55yIL11x2mbu+ebMUCrG3z5jhHvvBB9GFb045xd0+YYLbXqGC2750KfMnnzB/+qlsq1xZykquXMncsmXk+Tp3Zr7ySinB+fLLbvvcudHXBpgvukjOVbky84svStvbb7vXrldP2s49N/J7WLpUivEwM99yi9svZuY6ddz60fbrwAHm99+PbOvfX5abNiX22+UHyEvN2MJ4qdArSt44fJj5hReYN2yIbt++XQrcv/uutK1dKyJuMDWWp06NrGDGzHznna7IzZsXfd1rrnEF0I8ZM6IFtGxZ5jvukJvOcccx9+wp9ZEPH2Z+/XV/gTevAQPcc5vqXsWKuZXWypaVtoYNIz8LkbTn5EjdZnO++fOZK1VyP4f92rBBvjO7bcgQWf72W+TnPHgw+rvLb1ToFUUJzbZtzB9/HLx9wgTmjz7y3zZnDvOZZwY/aTAz9+4tJS1N+c2XXpL2Dz90BbRbN3f/du3c9i++YD7/fPf9hRdGntu0n3iia+GbV+XK8qSzaZPbtmIF8xVXuO9LlZLlffcxP/VU5PFpaVKSEGCuXt3dD2Bu0kSKxDOLyANSWrMgUaFXFCXlOHyYeflyEUbDE08w9+jB/PnnbtumTeJmufFGOWbfPnHr3HUX86JFked88UXmDh0iBXrQoGjr3LxuuUWeALztd98t5/M7plw55nvvlXWvO2vUKOmXee/tX34SS+hJtseGiHoC+DeA4pBC4U96tpcC8AaA9gAyAfRl5jXOtvsA/A3AIQBDmHlGvOulp6fzfG+8l6IoSkgWL5bon5NPluif77+XweYlS2RAuVgxiZIynHCCDBTfcYcMJj/2mMySXrlSJPvCC92kbV27SkqQmTNlYHrkSDl30IDsgAEy0F6xogxOH3ecDDib3E/Fi8vcjdmzZb5GrEybsSCiBcyc7rstntATUXEAvwE4G0AGpIbslWyVBCSiWwC0ZuabiKgfgN7M3JeImgN4G0BHALUBzARwEjPHzCitQq8oSn6zdq1ECRUrJlFLVarI+tKlEpJaunTk/kuXisBffHH0HIycHJmIt2eP5GX6/HMR8Z9+it8PuwZAo0YyfyI3Yh9L6MPE0XcEsIKZVzknmwTgYgB27deLAQx31icDeIGIyGmfxMz7AawmohXO+TylKhRFUQqW+vWjBRuIzF3kbQ/aVqKEWz3NrgGxbZuEiaalyUS3Dh0kb866dWLVb94sIaUHDkjcft26ubfoYxFG6OsAWGe9zwDgLQZ2ZB9mziGinQCqOu3feY71nQhORIMADAKAE8IkD1cURUlxzMQtQCZcAZKuw04QVxCkzIQpZh7DzOnMnF7dnlqoKIqi5IkwQr8egJ2xoq7T5rsPEZUAUBEyKBvmWEVRFCUfCSP08wA0JqKGRFQSQD8AUz37TAVwrbN+OYAvnHCfqQD6EVEpImoIoDEAT2kARVEUJT+J66N3fO5/BzADEl75OjMvI6JHIXGbUwH8B8CbzmDrNsjNAM5+70IGbnMADI4XcaMoiqIkl1Bx9AWNhlcqiqIkRqzwypQZjFUURVHyBxV6RVGUIo4KvaIoShEnJX30RLQFwNpcHl4NwNYkdifZpHr/AO1jMkj1/gHax2SQSv2rz8y+k5BSUujzAhHNDxqQSAVSvX+A9jEZpHr/AO1jMkj1/hnUdaMoilLEUaFXFEUp4hRFoR8Tf5dCJdX7B2gfk0Gq9w/QPiaDVO8fgCLoo1cURVEiKYoWvaIoimKhQq8oilLEKTJCT0Q9iehXIlpBRMMKsR+vE9FmIlpqtVUhos+I6HdnWdlpJyIa5fR5MRHlezkCIqpHRLOI6GciWkZEt6VgH0sT0Q9E9JPTx0ec9oZE9L3Tl3ecbKpwsqO+47R/T0QN8ruPznWLE9FCIvooRfu3hoiWENEiIprvtKXM7+xctxIRTSai5UT0CxF1TqU+ElET5/szr11EdHsq9TEUQVXDj6YXJKvmSgCNAJQE8BOA5oXUl64A2gFYarU9DWCYsz4MwFPO+nkApgMgAKcA+L4A+nc8gHbOenlIPeDmKdZHAlDOWU8D8L1z7XcB9HPaXwZws7N+C/D/7Z3Lq01hFMB/K9fzkuuVbimPCSMhidwkSpGMDEgxYGYiA3VT/gQxEErJwCvvuhPvkYHyfiSPopDrMkAZeSyDtQ7bcQ4Gzt3Lbv1qd77v27v2r7vuWWfvtU9nscfHq4Cj/RTrzcAhoMfn0fyeAWPr1sLE2c97ANjg40FARzTHgusAoBeYGNWxqXvZAv8oAPOAs4V5N9Bdos+kukT/EOj0cSfw0Md7sUbrvxzXj65nsMbvIR2BYcANrH3lW6CtPubYT2jP83GbHyct9poAXAQWAT3+xg7j5+dqlOjDxBlrUPS0/m8RybHOawlwJbJjs60qpZtGfW0b9qYtifGq+srHvcB4H5fq7SWEmdgVcyhHL4vcAvqA89gd2ztV/dzA46eexUCtZ3Er2QFsAb76fEwwPwAFzonIdbGezBArzpOBN8B+L4HtE5H2YI5FVgGHfRzVsSFVSfT/DWof86V/p1VEhgMngE2q+qG4L4Kjqn5R1RnYlfMcYFqZPkVEZDnQp6rXy3b5A12qOgtYCmwUkQXFnQHi3IaVOXer6kzgI1YG+U4ARwD8ecsK4Fj9viiOv6MqiT56b9rXItIJ4K99vl6Kt4gMxJL8QVU9GdGxhqq+Ay5jpZAOsZ7E9R7Neha3ivnAChF5BhzByjc7A/kBoKov/bUPOIV9YEaK8wvghape9flxLPFHcqyxFLihqq99HtGxKVVJ9H/T17ZMij1112F18dr6Wn9SPxd4X7gdbAkiIljrxwequj2o4zgR6fDxUOwZwgMs4a9s4tioZ3FLUNVuVZ2gqpOw/7VLqromih+AiLSLyIjaGKsv3yNQnFW1F3guIlN9aTHWdjSMY4HV/Cjb1FyiOTan7IcE/2rDnnY/wmq5W0v0OAy8Aj5hVyzrsXrsReAxcAEY7ccKsMud7wKz+8GvC7vNvAPc8m1ZMMfpwE13vAds8/UpWHP5J9gt9GBfH+LzJ75/Sj/GeyE/vnUTxs9dbvt2v/aeiBRnP+8M4JrH+jQwKqBjO3YHNrKwFsrxT1v+BEKSJEnFqUrpJkmSJGlCJvokSZKKk4k+SZKk4mSiT5IkqTiZ6JMkSSpOJvokSZKKk4k+SZKk4nwDchoUfplQj+cAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res =model.evaluate(X_testing, Y_testing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76_bNXw3URoh",
        "outputId": "20e681c1-c36a-46f7-974a-59f3cbba5013"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 3ms/step - loss: 2.2007 - accuracy: 0.6948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict new value\n",
        "test=X_testing[0]\n",
        "y_act=Y_testing[0]\n",
        "result=model.predict(test.reshape(1,8))\n",
        "result\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faa_FK3JUdcP",
        "outputId": "75f3a505-caee-42a9-a4f2-7dcd9b4b2a65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5292972 , 0.47070277]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "y_pred = np.round(result)\n",
        "print(\"Actual:\"+ str(y_act))\n",
        "print(\"Predicted:\"+str(y_pred))"
      ],
      "metadata": {
        "id": "my2NyecfUy67",
        "outputId": "804550ff-bf3e-49ae-dbf0-a5a788386711",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual:[1. 0.]\n",
            "Predicted:[[1. 0.]]\n"
          ]
        }
      ]
    }
  ]
}